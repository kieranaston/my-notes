{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kieran's Notes","text":"<p>All my notes in one place.</p> <p>Disclaimer: These are my personal notes, based on various sources. If you recognize any uncited content, please notify me for proper attribution.  </p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/","title":"Compute in the cloud","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-ec2","title":"Amazon EC2","text":"<p>EC2 refers to the servers that are used to run the virtual servers.</p> <p>AWS is already running a massive amount of compute capacity, and you can use however much of that capacity you want, whenever you want.</p> <p>You just request the EC2 instances you want, and they will boot up and be ready to use in just a few minutes.</p> <p>Once you're done you can easily terminate those instances.</p> <p>You only pay for what you use. You only pay for running instances, not stopped or terminated ones.</p> <p>EC2 runs on top of physical host machines managed by AWS using virtualization. You are sharing the host with other instances (virtual machines). A hypervisor on the host machine is responsible for sharing the underlying physical resources between the virtual machines.</p> <p>This is called multi-tenancy. Hypervisor coordinates this. Hypervisor isolates VMs from each other as they share resources from the host.</p> <p>One EC2 instance is not aware of other EC2 instances even though they are on the same host.</p> <p>When you provision an EC2 instance you can choose the operating system (Windows or Linux).</p> <p>Beyond the OS you also configure what software you want running on the instance.</p> <p>You might start with a small instance, and then if it starts to max out that server you can give the instance more memory and more CPU (vertically scaling an instance). You can do this whenever you need this.</p> <p>You also control networking (types of requests, publicly or privately accessible).</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-instance-types","title":"AWS instance types","text":"<p>Gives you flexibility of choosing appropriate distribution of resources for your applications.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#general-purpose","title":"General purpose","text":"<p>Balanced. Used for variety of diverse workloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#compute-optimized","title":"Compute optimized","text":"<p>Compute intensive tasks. Gaming servers, high performance computing (HPC), etc.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#memory-optimized","title":"Memory optimized","text":"<p>Good for memory intensive tasks, like high-performance databases.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#accelerated-computing","title":"Accelerated computing","text":"<p>Floating-point number calculations, graphics processing, data pattern matching.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#storage-optimized","title":"Storage optimized","text":"<p>Workloads that require high performance for locally stored data.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#ec2-pricing","title":"EC2 pricing","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#on-demand","title":"On-demand","text":"<p>Only pay for running duration. No long-term commitments. Good for getting up and running and testing workloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#savings-plans","title":"Savings plans","text":"<p>Low pricing, commitment to specific usage terms of a year or a few.</p> <p>Reduce you instance costs when you make an hourly spend commitment to an instance family and region for a 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#reserved-instances","title":"Reserved instances","text":"<p>Workloads with predictable usage. Can pay full upfront, partial upfront, and no upfront. Standard reserve instances require you to specify instance family and size, platform description, tenancy, and region.</p> <p>Available over 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#spot-instances","title":"Spot instances","text":"<p>Get spare computing capacity, but can be reclaimed any time it is needed with a 2 minute warning. Good for batch owrkloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#dedicated-hosts","title":"Dedicated hosts","text":"<p>Usually for meeting certain compliance requirements, and nobody else will be using that host.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#scaling-amazon-ec2","title":"Scaling Amazon EC2","text":"<p>Scalability and elasticity refers to how capacity can grow and shrink based on business needs.</p> <p>Do not want to end up with data centers under 10% average utilization for fear of missing out on peak demand.</p> <p>Amazon EC2 auto scaling enables you to automatically add or remove Amazon EC2 instances in response to changing application demand.</p> <p>Dynamic scaling responds to changing demand.</p> <p>Predictive scaling automatically schedules the right number of Amazon EC2 instances based on predicted demand.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#auto-scaling","title":"Auto scaling","text":"<p>When creating an auto scaling group you can set the minimum number of Amazon EC2 instances that start up as soon as you create the auto scaling group (minimum capacity). You can also set the desired capacity even though your application needs a minimum of a single Amazon EC2 instance to run (desired capacity defaults to minimum capacity if not specified). Next you can set the maximum capacity so that you can scale out with demand but not past a maximum.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#elastic-load-balancing","title":"Elastic load balancing","text":"<p>Say we have an uneven distribution of traffic across our EC2 instances. We need a host to direct customers to different lines to place their order, managing the distribution of traffic.</p> <p>We apply this to AWS environments as elastic load balancing.</p> <p>Load balancer is application that takes in requests and routes them to different instances to be processed. Many off the shelf solutions that work great with AWS.</p> <p>AWS can provide this service in the form of Elastic Load Balancing. This is an AWS managed service that addresses issue of load balancing.</p> <p>Because it runs at the region level rather than on specific EC2 instances, the service is automatically highly available with no additional effort on your part.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#messaging-and-queueing","title":"Messaging and queueing","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#tightly-coupled-architecture","title":"Tightly-coupled architecture","text":"<p>If a single component has a problem it causes problems for other components or the whole system.</p> <p>Applications made up of tightly coupled components are monolithic.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#loosely-coupled-architecture","title":"Loosely coupled architecture","text":"<p>Single failure won't cause cascading failures.</p> <p>You have a queue in the middle where messages go to eventually be processed. If a given application can't process the message, it stays in the queue until it is processed by another application.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-sqs-amazon-simple-queue-service","title":"Amazon SQS (Amazon Simple Queue Service)","text":"<p>Allows you to send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available.</p> <p>Payload is the data inside the message, and it is protected until delivery.</p> <p>SQS queues are where messages are placed until they are processed.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-sns-amazon-simple-notification-service","title":"Amazon SNS (Amazon Simple Notification Service)","text":"<p>Amazon SNS can send out messages but it can also send out notifications to end users. Uses a publish subscribe model.</p> <p>Can make an Amazon SNS topic: a channel for messages to be delivered. Can then configure subscribers for that topic, and publish messages for subscribers.</p> <p>Subscribers can be web servers, email addresses, AWS Lambda functions, or several other options.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#additional-compute-services","title":"Additional compute services","text":"<p>Though EC2 is good in a lot of cases, depending on your use case you might want an alternative.</p> <p>When using EC2 you are responsible for setting up and managing your instances over time.</p> <p>AWS offers multiple serverless compute options, meaning that you don't see or access the underlying infrastructure tha`t is hosting your application. Instead, all management of the underlying environment is taken care of. All you need to do is focus on your application.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#serverless-computing","title":"Serverless computing","text":"<p>When computing with virtual servers you have to think about the servers and code, while when serverless computing you only have to think about the code.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-lambda","title":"AWS Lambda","text":"<p>AWS Lambda is a serverless compute option. More suited for quick processes, not something like deep learning.</p> <p>Allows you to run code without needing to provision or manage servers. You can run code for virtually any type of application or backend service, all with zero administration.</p> <p>Setup:</p> <ol> <li>Upload code to Lambda</li> <li>Set code to trigger from an event source</li> <li>Code only runs when triggered</li> <li>Pay only for the compute time you use</li> </ol>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-elastic-container-service-amazon-ecs","title":"Amazon Elastic Container Service (Amazon ECS)","text":"<p>Containers provide you with a standard way to package your application's code and dependencies into a single object. Can also use containers for processes and workflows in which there are essential requirements for security, reliability, and scalability.</p> <p>Using containers could delp to ensure that the application's environment remains consistent regardless of deployment.</p> <p>ECS supports Docker containers. With Amazon ECS you can use API calls to launch and stop Docker-enabled applications.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-elastic-kubernetes-service-amazon-eks","title":"Amazon Elastic Kubernetes Service (Amazon EKS)","text":"<p>Amazon EKS is a fully managed service that you can use to run Kubernetes on AWS. Kubernetes is open-source software that enables you to deploy and manage containerized applications at scale.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-fargate","title":"AWS Fargate","text":"<p>Serverless compute engine for containers. Works with both Amazon ECS and Amazon EKS. When using Fargate, you do not need to provision or manage servers. Fargate manages the server infrastructure for you.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/","title":"Global infrastructure and reliability","text":"<p>High availability and fault tolerance is important. AWS operates in many regions to support this.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-global-infrastructure","title":"AWS global infrastructure","text":"<p>Events could happen that could cause lost connection to a certain data center. Most businesses end up just using backups and hoping for no disasters.</p> <p>If disaster strikes, AWS data centers will be fine. They build large data centers in central, business heavy locations.</p> <p>Each of these regions contain multiple data centers that have all the compute, storage, and services you need. Each region is connected to each other region through a high speed fiber network. You get to choose which region you want to run out of. None of your data will come into or out of that region. It is isolated.</p> <p>You might have certain government compliance requirements. E.g., any data in the Frankfurt region never leaves the Frankfurt region, unless you explicitly (with proper credentials) request an export.</p> <p>Proximity and compliance both matters. Latency is always a factor.</p> <p>Sometimes the obvious region choice may not have all of the AWS services/features available. Sometimes brand new services require new hardware and are difficult to implement everywhere.</p> <p>If budget is primary concern, you might want to operate in a different country with different pricing.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#availability-zones","title":"Availability zones","text":"<p>You don't want ot run your business out of a single building, or a single location.</p> <p>AWS has lots of data centers all around the world. Each region is made up of multiple data centers. We refer to these groups of data centers as availability zones (one or more data centers with redundant power, networking, connectivity, etc.).</p> <p>Each region consists of multiple isolated availability zones.</p> <p>As best practice it is recommended that you always run across at least two availability zones in a region, in case one gets taken out.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#edge-locations","title":"Edge locations","text":"<p>What if there is not an obvious answer to the problem of proximity for your business. You can instead cache a copy of your data locally, close to cutomers around the world. This uses concept of Content Delivery Networks (CDNs).</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#amazon-cloudfront","title":"Amazon Cloudfront","text":"<p>Service that helps deliver data, video, applications and APIs to customers around the world with low latency and high transfer speeds. Uses edge locations all around the world to accelerate communications with users no matter where they are.</p> <p>Can push content from a region to a colletion of edge locations around the world to accelerate communication and content delivery.</p> <p>AWS edge locations also run DNS called Amazon Route 53, directing customers to the correct web locations with reliably low latency.</p> <p>AWS Outposts involve basically installing a fully operational mini region right inside your own data center. If you have specific problems that can only be solved by staying within your own building, it would be right for you.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#how-to-provision-aws-resources","title":"How to provision AWS resources","text":"<p>In AWS everything is an API call.</p> <p>You can use tools like:</p> <ul> <li>AWS Management Console</li> <li>AWS Command Line Interface (CLI)</li> <li>AWS Software Development Kits (SDKs)</li> <li>Various other tools</li> </ul> <p>To create requests to send to the AWS APIs to creat and manage AWS resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-management-console","title":"AWS Management console","text":"<p>Browser based, manage visually. Useful for building test environments, AWS bills, view monitoring, and working with non-technical resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-cli","title":"AWS CLI","text":"<p>Allows you to make API calls using the terminal on your machine. Makes actions scriptable and repeatable.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-sdks","title":"AWS SDKs","text":"<p>Allow you to interact through various programming languages.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-elastic-beanstalk","title":"AWS Elastic Beanstalk","text":"<p>Allows you to provision Amazon EC2 based environments. You can just provide your application code and desired configurations to AWS Elastic Beanstalk service, which then takes that info and builds out your environment for you. Can also easily save environment configurations so that they can be deployed again.</p> <p>Gives convenience of not having to provision and manage these things separately, while still giving the visibility and control of underlying resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-cloudformation","title":"AWS Cloudformation","text":"<p>Infrastructure as code tool. Allows you to define wide variety of AWS resources with JSON or YAML text-based documents called cloud-formation templates. Allows you to define what you want to build without specifying exatly how you want to build it.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/","title":"Introduction to Amazon Web Services (AWS)","text":"<ul> <li>Amazon EC2 is a virtual server</li> <li>Client-server model: Client can be a web browser or desktop app that person interacts with, server can be services such as Amazon EC2 (a virtual server)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#deployment-models","title":"Deployment models","text":""},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#cloud-based-deployment","title":"Cloud based deployment","text":"<ul> <li>Run all parts of the application in the cloud</li> <li>Migrate existing applications to the cloud</li> <li>Design and build new applications in the cloud</li> <li>Can build applications on low-level or high-level infrastructure depending on how much management you want to do yourself</li> </ul> <p>Example: Company might create an application consisting of virtual servers, databases, and networking components that are fully based in the cloud</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#on-premises-deployment","title":"On-premises deployment","text":"<ul> <li>Deploy resources by using virtualization and resource management tools</li> <li>Increase resource utilization by using application management and virtualization technologies</li> <li>Also known as private cloud deployment</li> </ul> <p>Example: You might have applications that run on technology that is fully kept in your on-premises data center. Incorporation of application management and virtualization technologies helps to increase resource utilization</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#hybrid-deployment","title":"Hybrid deployment","text":"<ul> <li>Connect cloud-based resources to on-premises infrastructure</li> <li>Integrate cloud-based resources with legacy IT applications</li> </ul> <p>Example: You might have legacy applications that are better maintained on premises, or government regulations require your business to keep certain records on premises. Suppose a company wants to use cloud services that can automate batch data processing and analytics. However, the company has several legacy applications that are more suitable on premises and will not be migrated to the cloud. With hybrid deployment, the company would be able to keep the legacy applications on premises while benefitting from the data and analytics services that run in the cloud.</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#benefits-of-cloud-computing","title":"Benefits of cloud computing","text":""},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#trade-upfront-expense-for-variable-expense","title":"Trade upfront expense for variable expense","text":"<ul> <li>Upfront costs like data centers, physical servers, etc. gone</li> <li>Only pay for resources you consume</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#stop-spending-money-to-run-and-maintain-data-centers","title":"Stop spending money to run and maintain data centers","text":"<ul> <li>Eliminates requirement to spend more money and time managing infrastructure and servers</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#stop-guessing-capacity","title":"Stop guessing capacity","text":"<ul> <li>Don't have to predict how much infrastructure capacity you will need before deploying an application</li> <li>Can deploy Amazon EC2 (Elastic Compute Cloud) when needed, and pay only for the compute time you use</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#benefit-from-massive-economies-of-scale","title":"Benefit from massive economies of scale","text":"<ul> <li>Because lots of customers can aggregate in the cloud, providers, such as AWS, can achieve higher economies of scale (translates to lower prices)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#increase-speed-and-agility","title":"Increase speed and agility","text":"<ul> <li>Flexibility, easier to develop and deploy applications</li> <li>More time to experiment and innovate (access new resources within minutes)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#go-global-in-minutes","title":"Go global in minutes","text":"<p>Deploy applications to customers around the world quickly, while providing them with low latency.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/","title":"Networking","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-virtual-private-cloud-vpcs","title":"Amazon Virtual Private Cloud (VPCs)","text":"<p>A VPC lets you provision a logically isolated section of the AWS cloud where you can launch AWS resources in a virtual network that you define.</p> <p>The private and public grouping of resources are known as subnets, and they are ranges of IP addresses in your VPCs.</p> <p>Essentially your own private network in AWS. Allows you to define your private IP range for your AWS resources, and you place things like EC2 instances and ELBs (Elastic Load Balancers) inside of your VPC.</p> <p>For some VPCs you might have internet-facing resources that the public should be able to reach, like a public website. In other scenarios you might have resources that you only want to be reachable if someone is logged into your private network, such as an HR application or backend database.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#internet-gateway-igw","title":"internet gateway (IGW)","text":"<p>In order to allow traffic from the public internet to flow into and out of your VPC, you must attach what is called an internet gateway, or IGW, to your VPC. This is like a doorway that is open to the public.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#virtual-private-gateway","title":"Virtual private gateway","text":"<p>If we don't want just anyone to be able to access these resources, we want a private gateway that only lets in people coming from an approved network.</p> <p>This is called a virtual private gateway, and allows you to create a VPN connection between a private network (like your on-premises data center) and your VPC.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#direct-connect","title":"Direct connect","text":"<p>The problem with using a VPN connection is they use bandwidth being shared by many people using the internet. To get around this you can use AWS direct connect, which allows you to establish a completely private, dedicated fiber connection from your data center to AWS. This can help with high regulatory and compliance needs, as well as any bandwidth issues.</p> <p>One VPC might have multiple types of gateways attached for multiple types of resources all residing in the same VPC, just in different subnets.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#subnets-and-network-access-control-lists","title":"Subnets and network access control lists","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#subnets","title":"Subnets","text":"<p>Public subnets contain resources that need to be accessible by the public, such as an online store's website.</p> <p>Private subnets contain resources that should be accessible only through your private network, such as a database that contains customers' personal information and order histories.</p> <p>Internet gateways only cover the perimeter. We need to cover other layers of security as well.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#network-hardening","title":"Network hardening","text":"<p>The only technical reason to use subnets in a VPC is to control access to gateways. Subnets can also control packet permissons. Every packet that tried to cross over the subnet boundary gets checked against the network access control list (network ACL). This is to see if the packet has permissions to leave or enter the subnet. Network ACL kinda acts like a border control officer.</p> <p>By default, your AWS account's network access control list is stateless and allows all inbound and outbound traffic.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#security-groups","title":"Security groups","text":"<p>This does not solve the problem of different levels of security for different EC2 instances within the subnet though. You need instance-level security as well. For this we can use security groups. You can modify these groups to accept specific types of traffic. These are like a doorman at a building or hotel. You may been let into the country by the border control officer, but the doorman of the building might turn you away.</p> <p>By default, security groups allow any traffic out and deny all incoming traffic. Key difference between network ACL and security group is a security group is stateful, meaning that it remembers what to let in or out. A network ACL checks every packet regardless.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#global-networking","title":"Global networking","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-route-53","title":"Amazon Route 53","text":"<p>Highly available and scalable DNS. Think of it as a translation service, but instead of translating languages, it translates website names into IP addresses.</p> <p>Some of the route 53 routing policies:</p> <ul> <li>Latency based</li> <li>Geolocation DNS</li> <li>Direct traffic based on where customer is located</li> <li>Geoproximity</li> <li>Weighted round robin</li> </ul> <p>You can also use route 53 to buy and manage domain names.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-cloudfront","title":"Amazon Cloudfront","text":"<p>Using edge locations with cached content to better serve content around the world using CDNs. A CDN is a network that delivers edge content to users based on their geographic location.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/","title":"Where in the genome does DNA replication begin?","text":"<p>Replication begind in a genomic region called the replication origin (denoted \\(oriC\\)).</p> <p>In the context of gene therapy it is important to figure out where the \\(oriC\\) is within the genome so that it can be preserved. This is because it is necessary for gene replication, which is an important part of gene therapy.</p> <p>Research has shown that the region of the bacterial genome encoding \\(oriC\\) is typically a few hundred nucleotides long.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#finding-the-oric","title":"Finding the \\(oriC\\)","text":"<p>One way we can try to find the \\(oriC\\) is by looking for the \\(DnaA\\) box, a DNA sequence that is essentially a message telling the \\(DnaA\\) protein: \"bind here!\"</p> <p>We want to look for something that stands out in \\(oriC\\), in other words, some sort of pattern.</p> <p>One way we can define this problem is as a pattern counting problem, where we search for the most frequent \\(k\\)-mers, or, strings of length \\(k\\).</p> <p>We can use the following algorithm:</p> <pre><code>def pattern_count(text, pattern):\n    count = 0\n    for i in range(0, len(text)-len(pattern)):\n        if text[i:(i+len(pattern))] == pattern:\n            count += 1\n    return count\n</code></pre>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#the-frequent-words-problem","title":"The Frequent Words problem","text":"<p>Let us extend this further. We can generalize to wanting to find the most frequent \\(k\\)-mer for all values of \\(k\\) possible for the text.</p> <p>We say that \\(Pattern\\) is a most frequent \\(k\\)-mer in \\(Text\\) if it mazimizes <code>pattern_count(text, pattern)</code> among all \\(k\\)-mers.</p> <p>So our problem is as follows:</p> <p>Input: A string \\(Text\\) and an integer \\(k\\)</p> <p>Output: All most frequent \\(k\\)-mers in \\(Text\\)</p> <p>There will be \\(|Text|-k+1\\) \\(k\\)-mers to check in a given string \\(Text\\).</p> <p>To implement this algorithm <code>frequent_words</code> we need to store an array <code>count</code> containing the number of occurrences of each pattern \\(Pattern = Text(i,k)\\), where <code>count[i]</code> stores <code>count(text, pattern)</code> for \\(Pattern = Text(i,k)\\). So if we have a pattern of length 3, <code>count[2]</code> would be the number of occurrences of the substring from index 2 to index (2 + 3) - 1 = 4.</p> <p>Here is the algorithm:</p> <pre><code>def frequent_words(text, k):\n    count = []\n    frequent_patterns = []\n    max_count = 0\n    for i in range(0, len(text)-k):\n        pattern = text[i:(i+k)]\n        count.append(pattern_count(text, pattern))\n        if count[i] &gt; max_count:\n            max_count = count[i]\n    for i in range(0, len(text)-k):\n        if count[i] == max_count:\n            frequent_patterns.append(text[i:(i+k)])\n    frequent_patterns = list(dict.fromkeys(frequent_patterns))\n    return frequent_patterns\n</code></pre> <p>This works, but it is not very efficient.</p> <p>Each \\(k\\)-mer requires \\(|Text| - k + 1\\) checks, each requiring as many as \\(k\\) comparisons, so overall # of steps of <code>pattern_count(text, pattern)</code> is \\((|Text| - k + 1) \\cdot k\\).</p> <p>Additionally, <code>frequent_words</code> must call <code>pattern_count</code> \\(|Text| - k + 1\\) times (once for each \\(k\\)-mer of \\(Text\\)), so its overall number of steps is \\((|Text| - k + 1) \\cdot (|Text| - k + 1) \\cdot k\\).</p> <p>To simplify, its complexity is \\(\\mathcal{O}(|Text|^2\\cdot k)\\).</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#another-way-of-doing-this","title":"Another way of doing this","text":"<p>With the goal of making our algorithm more efficient, we can address the main issue: we look through the entire string for every different \\(k\\)-mer pattern. Our new idea is to pass through the string once for each \\(k\\), maintaining a count of each possible \\(k\\)-mer and adding to each \\(k\\)-mer's count whenever we pass over it. Since these strings are made up of four different possible characters, we will have \\(4^k\\) possible \\(k\\)-mers for each value of \\(k\\).</p> <p>We define the frequency array of a string \\(Text\\) as an array of length \\(4^k\\), where the \\(i\\)-th element of the array holds the number of times that the \\(i\\)-th \\(k\\)-mer (in the lexographic order) appears in \\(Text\\).</p> <p>To make this work we need to be able to transform strings to integers and back to strings. We can figure out the possible \\(k\\)-mers, order them lexographically, then number them based on that ordering. Based on that numbering we can encode our string as an integer, where each \\(k\\)-mer is described by its number in the lexographic ordering.</p> <p>The following algorithms are for encoding and decoding out representations:</p> <p>Encoding:</p> <pre><code>def pattern_to_number(pattern):\n    if not pattern:\n        return 0\n    symbol_to_number = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n    result = 0\n    for char in pattern:\n        result = result * 4 + symbol_to_number[char]\n    return result\n</code></pre> <p>Decoding:</p> <pre><code>def number_to_pattern(index, k):\n    if k == 0:\n        return \"\"\n    number_to_symbol = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n    prefix_index = index // 4\n    remainder = index % 4\n    symbol = number_to_symbol[remainder]\n    if k == 1:\n        return symbol\n    else:\n        prefix_pattern = number_to_pattern(prefix_index, k-1)\n        return prefix_pattern + symbol\n</code></pre> <p>We can now move on to the problem of generating frequency arrays. We can first initialize every \\(4^k\\) elements in the frequency array to zero, then make a single pass down the string. For each \\(k\\)-mer we encounter, we add 1 to the value of the frequency array corresponding to it.</p> <p>If working in Python we can use a dict for our frequency array:</p> <pre><code>def frequency_array(k):\n    frequencies = {}\n    for i in range(0, (4**k)):\n        frequencies[number_to_pattern(i, k)] = 0\n    return frequencies\n</code></pre> <p>This uses our previously built <code>number_to_pattern</code> function to populate our dictionary with keys corresponding to each possible \\(k\\)-mer, in lexicographical order.</p> <p>We can now put it all together with a complete algorithm that is faster than our original solution:</p> <pre><code>def faster_frequent_words(text, k):\n    frequencies = frequency_array(k)\n    for i in range(len(text) - k + 1):\n        frequencies[text[i:i+k]] += 1\n    max_value = max(frequencies.values())\n    print(frequencies)\n    return [key for key, value in frequencies.items() if value == max_value]\n</code></pre> <p>This algorithm initializes a dict of all possible \\(k\\)-mers. It then iterates through \\(Text\\) and adds each \\(k\\)-mer occurrence to the frequency dict. We then get the maximum value of the frequency dict, and iterate through the frequency dict to check for strings that match that maximum value. Strings that have occurrences equal to the max are returned. </p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#references","title":"References","text":"<p>Compeau, P., &amp; Pevzner, P. (2015). Bioinformatics algorithms: An active learning approach (Vol. 1). Active Learning Publishers.</p>"},{"location":"linux-essentials/linux-administration/utility-commands-user-management/","title":"Utility commands and user management","text":""},{"location":"linux-essentials/linux-administration/utility-commands-user-management/#linux-file-editor","title":"Linux file editor","text":"<p>Several standard text editors on most Linux systems:</p> <ul> <li><code>vi</code> visual editor</li> <li><code>ed</code> standard line editor</li> <li><code>ex</code> extended line editor</li> <li><code>emacs</code> a full screen editor</li> <li><code>pico</code> beginner's editor</li> <li><code>vim</code> advanced version of vi</li> </ul> <p>Will focus on <code>vi</code> because it is usually available on every Linux system and is easy to learn.</p>"},{"location":"linux-essentials/linux-administration/utility-commands-user-management/#most-common-vi-commands","title":"Most common <code>vi</code> commands","text":"<p><code>i</code> insert <code>Esc</code> escape out of any mode <code>r</code> replace <code>d</code> delete <code>:q!</code> quit without saving <code>:wq!</code> quit and save</p> <p>When you enter <code>vi</code> you will be in command mode. The other mode is the typing (insert) mode.</p> <p>To enter typing mode you hit <code>i</code> or \"insert\".</p> <p>To save you could shift + z z. Or you could do <code>:wq!</code></p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/","title":"Commands and permissions","text":"<p>Commands syntax:</p> <pre><code>command option(s) argument(s)\n</code></pre>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#options","title":"Options","text":"<p>Options modify the way a command works, and usually consist of a dash followed by a single letter.</p> <p>Multiple options can be grouped together after a single hyphen.</p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#arguments","title":"Arguments","text":"<p>Most commands are used with one or more arguments.</p> <p>Some commands assume a default argument if none is supplied.</p> <p>Arguments are optional for some commands and required by others.</p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#useful-commands","title":"Useful commands","text":"<p><code>whoami</code> to determine which user you are.</p> <p><code>pwd</code> to display your directory.</p> <p><code>cd</code> to move about directories.</p> <p><code>ls</code> to see items within working directory.</p> <p><code>cp</code> to copy a file from one directory to another.</p> <ul> <li>The third column in file info tells you the owner of the file.</li> <li>The fourth column is the group name for that file.</li> <li>Fifth column gives number of bytes for the file.</li> <li><code>ll</code> gives same result as <code>ls -l</code></li> </ul> <p><code>rm -f</code> to delete a file without confirming, <code>rm -r</code> to delete a directory.</p> <p><code>mkdir</code> to create a directory.</p> <p><code>man</code> with a command as argument to see man page for a command.</p> <p><code>date</code> gives the date on your system.</p> <p><code>more</code> gives output one page at a time. Piping with more is useful.</p> <p><code>tail</code> gives last line of an output. Also useful in piping.</p> <p><code>cat</code> reads contents of a file.</p> <p>To become a super user (root user) use <code>sm -</code> and enter your password.</p> <ul> <li>To leave root user account: <code>exit</code></li> </ul>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#permissions","title":"Permissions","text":"<p><code>r</code> - read <code>w</code> - write <code>x</code> - execute = running a program</p> <p>Each permission can be controlled at three different levels:</p> <p><code>u</code> - user <code>g</code> - group <code>o</code> - other = everyone on the system</p> <p>To see file or directory permissions run <code>ls -l</code>:</p> <p>Example: <code>-rwxrwxrwx</code></p> <p>First bit indicates a file, next three bits are user permissions, then next three are group, and last three are permissions for others.</p> <p><code>chmod</code> can be used to change permissions.</p> <p>Example: Removing group write permissions from file <code>testfile</code>: <code>chmod g-w testfile</code> Example: Removing write permissions for everyone from file <code>testfile</code>: <code>chmod a-w testfile</code></p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#file-ownership","title":"File ownership","text":"<p><code>chown</code> changes the ownership of a file.</p> <p>Example: To change the ownership from a user to root: <code>chown root testfile</code></p> <p><code>chgrp</code> changes the group ownership of a file.</p> <p>The <code>-R</code> option changes ownership recursively (everything within will also have ownership changed).</p> <p>Note: If a file you do not have ownership of is within a directory that you have permissions for, you can still delete/make changes to it. For this reason is it often important to perform recursive ownership changes to ensure they are properly applied for your case.</p> <p>Source: Linux for Absolute Beginners: Commands and Permissions by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/file-commands/","title":"File commands","text":""},{"location":"linux-essentials/linux-command-line/file-commands/#file-display-commands","title":"File display commands","text":"<ul> <li><code>cat</code> views entire content</li> <li><code>more</code> views one page at a time</li> <li><code>less</code> views content in reverse order, one page at time</li> <li><code>head</code> gives the first few lines</li> <li><code>tail</code> gets you the last lines of a file</li> </ul>"},{"location":"linux-essentials/linux-command-line/file-commands/#file-maintenance-commands","title":"File maintenance commands","text":"<ul> <li><code>cp</code> copies a file from one location to another</li> <li><code>rm</code> removes a file</li> <li><code>mv</code> used to move location of file from one to another, or rename it</li> <li><code>mkdir</code> makes a directoy</li> <li><code>rmdir</code> or <code>rm -r</code> removes directory</li> <li><code>chgrp</code> changes group ownership</li> <li><code>chown</code> changes ownership</li> </ul> <p>Source: Linux for Absolute Beginners: File Commands and Filters by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/","title":"File comparison and splitting","text":""},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#cut-command","title":"Cut command","text":"<p>Cut is a command utility that allows you to cut parts of lines from specific files or piped data and print the result to standard output.</p> <p>Can be used to cut parts1 of a line by a delimiter, byte position, and character.</p> <p><code>cat -c1 filename</code> list one character <code>cut -c1,2,4</code> pick and choose character(s) <code>cut -c1-3 filename</code> list range of characters <code>cut -c1-3, 6-8 filename</code> list by specific range of characters <code>cut -b1-3 filename</code> list by byte size <code>cut -d: -f 6 /etc/passwd</code> list first 6th column separated by : <code>cut -d: -f 6-7 /etc/passwd</code> list first 6 and 7th column separated by : <code>ls -l | cut -c2-4</code> only print user permissions of files/dir</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#compare-files","title":"Compare files","text":"<p><code>diff</code> compares line by line <code>cmp</code> compares byte by byte</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#comtining-and-plitting-files","title":"Comtining and plitting files","text":"<p>Multiple files can be combined into one, and one file can be split into multiple files.</p> <p>In times when we have huge files, there are times when we need to either split them or compress them to send them places.</p> <p><code>split -l 2 countries sep</code> splits the file countries into files with name <code>sep</code> containing 2 lines each from original countries file</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#linux-vs-windows-commands","title":"Linux vs. Windows commands","text":"<p>Listing of a directory: <code>dir</code> vs <code>ls -l</code> Rename a file: <code>ren</code> vs <code>mv</code> Copy a file: <code>copy</code> vs <code>cp</code> Move file: <code>move</code> vs <code>mv</code> Clear screen: <code>cls</code> vs <code>clear</code> Delete file: <code>del</code> vs <code>rm</code> Compare contents of files: <code>fc</code> vs <code>diff</code> Search for a word/string in a file: <code>find</code> vs <code>grep</code> Display command help: <code>command /?</code> vs <code>man command</code> Displays your location in the file system: <code>chdir</code> vs <code>pwd</code> Displays the time: <code>time</code> vs <code>date</code></p> <p>Source: Linux for Absolute Beginners: File Comparison and Splitting by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/","title":"Help commands and pipes","text":""},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#help-commands","title":"Help commands","text":"<p>3 types of help commands:</p> <ul> <li><code>whatis command</code></li> <li>Gives shorter version of command info</li> <li><code>command --help</code></li> <li>Longer version of help for command</li> <li><code>man command</code></li> <li>Full info for command</li> </ul>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#tab-and-up-arrow","title":"Tab and up arrow","text":"<p>Tab completes available commands, files, or directories.</p> <p>Up arrow gives the last executed command.</p>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#pipes","title":"Pipes","text":"<p>Pipes are used to connect the output of one command to the input of another command.</p> <p>The symbol for a pipe is <code>|</code>. Syntax for using pipes is:</p> <pre><code>command1 [arguments] | command2 [arguments]\n</code></pre>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#adding-text-to-files","title":"Adding text to files","text":"<p>3 simple ways:</p> <ul> <li><code>vi</code> editor</li> <li>Redirect command output <code>&gt;</code> or <code>&gt;&gt;</code></li> <li><code>echo &gt;</code> or <code>&gt;&gt;</code></li> </ul> <p>Example using redirect: <code>echo \"Jerry is the main character in Seinfeld\" &gt; jerry</code> populates file <code>jerry</code> with that text.</p> <p>Doing it with <code>&gt;</code> will overwrite contents. <code>&gt;&gt;</code> will add to the existing contents.</p> <p>Can also send the output of a command to a file this way.</p> <p>Source: Linux for Absolute Beginners: Help Command and Pipes by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/","title":"Text and grep commands","text":""},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#filterstext-processors-commands","title":"Filters/text processors commands","text":"<ul> <li><code>cut</code> cut output of command</li> <li><code>awk</code> list by the columns</li> <li><code>grep</code> and <code>egrep</code> search by keywords</li> <li><code>sort</code> sorts output</li> <li><code>uniq</code> no duplicates in output</li> <li><code>wc</code> word count</li> </ul> <p>Example of <code>grep</code>: To search for directories with user read and write permissions: <code>ls -l | grep drw</code></p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#grep-usage","title":"<code>grep</code> usage","text":"<p><code>grep keyword file</code> gives only the lines of <code>file</code> that contain <code>keyword</code> <code>grep -c keyword file</code> this searches for a keyword and counts it <code>grep -i KEYword file</code> searches for keyword but ignore case <code>grep -n keyword file</code> displays the matched lines and line numbers <code>grep -v keyword file</code> get everything but the search keyword <code>grep keyword file | awk '(print $1)'</code> gives only first columns of the lines returned <code>ls -l | grep Desktop</code> only pull results that include \"Desktop\" <code>egrep -i \"keyword|keyword2\" file</code> gives all lines matching either of the keywordsx</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#wc-usage","title":"<code>wc</code> usage","text":"<p>Reads either standard input or list of files and generates: newline count, word count, byte count.</p> <p><code>wc file</code> checks file line count, word count, byte count <code>wc -l file</code> gets number of lines in a file <code>wc -w file</code> gets number of words in a file <code>wc -b file</code> gets number of bytes in a file</p> <p><code>ls -l | wc -l</code> gives the number of files/directories you have within a location (plus 1 extra line counted)</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#awk-usage","title":"<code>awk</code> usage","text":"<p>Most of the time <code>awk</code> is used to extract fields from a file or from an output.</p> <p>Source: Linux for Absolute Beginners: Text and Grep Commands by Imran Afzal, Allison.</p>"}]}