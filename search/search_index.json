{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kieran's Notes","text":"<p>All my notes in one place.</p> <p>Disclaimer: These are my personal notes, based on various sources. If you recognize any uncited content, please notify me for proper attribution.  </p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/","title":"Compute in the cloud","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-ec2","title":"Amazon EC2","text":"<p>EC2 refers to the servers that are used to run the virtual servers.</p> <p>AWS is already running a massive amount of compute capacity, and you can use however much of that capacity you want, whenever you want.</p> <p>You just request the EC2 instances you want, and they will boot up and be ready to use in just a few minutes.</p> <p>Once you're done you can easily terminate those instances.</p> <p>You only pay for what you use. You only pay for running instances, not stopped or terminated ones.</p> <p>EC2 runs on top of physical host machines managed by AWS using virtualization. You are sharing the host with other instances (virtual machines). A hypervisor on the host machine is responsible for sharing the underlying physical resources between the virtual machines.</p> <p>This is called multi-tenancy. Hypervisor coordinates this. Hypervisor isolates VMs from each other as they share resources from the host.</p> <p>One EC2 instance is not aware of other EC2 instances even though they are on the same host.</p> <p>When you provision an EC2 instance you can choose the operating system (Windows or Linux).</p> <p>Beyond the OS you also configure what software you want running on the instance.</p> <p>You might start with a small instance, and then if it starts to max out that server you can give the instance more memory and more CPU (vertically scaling an instance). You can do this whenever you need this.</p> <p>You also control networking (types of requests, publicly or privately accessible).</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-instance-types","title":"AWS instance types","text":"<p>Gives you flexibility of choosing appropriate distribution of resources for your applications.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#general-purpose","title":"General purpose","text":"<p>Balanced. Used for variety of diverse workloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#compute-optimized","title":"Compute optimized","text":"<p>Compute intensive tasks. Gaming servers, high performance computing (HPC), etc.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#memory-optimized","title":"Memory optimized","text":"<p>Good for memory intensive tasks, like high-performance databases.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#accelerated-computing","title":"Accelerated computing","text":"<p>Floating-point number calculations, graphics processing, data pattern matching.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#storage-optimized","title":"Storage optimized","text":"<p>Workloads that require high performance for locally stored data.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#ec2-pricing","title":"EC2 pricing","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#on-demand","title":"On-demand","text":"<p>Only pay for running duration. No long-term commitments. Good for getting up and running and testing workloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#savings-plans","title":"Savings plans","text":"<p>Low pricing, commitment to specific usage terms of a year or a few.</p> <p>Reduce you instance costs when you make an hourly spend commitment to an instance family and region for a 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#reserved-instances","title":"Reserved instances","text":"<p>Workloads with predictable usage. Can pay full upfront, partial upfront, and no upfront. Standard reserve instances require you to specify instance family and size, platform description, tenancy, and region.</p> <p>Available over 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#spot-instances","title":"Spot instances","text":"<p>Get spare computing capacity, but can be reclaimed any time it is needed with a 2 minute warning. Good for batch owrkloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#dedicated-hosts","title":"Dedicated hosts","text":"<p>Usually for meeting certain compliance requirements, and nobody else will be using that host.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#scaling-amazon-ec2","title":"Scaling Amazon EC2","text":"<p>Scalability and elasticity refers to how capacity can grow and shrink based on business needs.</p> <p>Do not want to end up with data centers under 10% average utilization for fear of missing out on peak demand.</p> <p>Amazon EC2 auto scaling enables you to automatically add or remove Amazon EC2 instances in response to changing application demand.</p> <p>Dynamic scaling responds to changing demand.</p> <p>Predictive scaling automatically schedules the right number of Amazon EC2 instances based on predicted demand.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#auto-scaling","title":"Auto scaling","text":"<p>When creating an auto scaling group you can set the minimum number of Amazon EC2 instances that start up as soon as you create the auto scaling group (minimum capacity). You can also set the desired capacity even though your application needs a minimum of a single Amazon EC2 instance to run (desired capacity defaults to minimum capacity if not specified). Next you can set the maximum capacity so that you can scale out with demand but not past a maximum.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#elastic-load-balancing","title":"Elastic load balancing","text":"<p>Say we have an uneven distribution of traffic across our EC2 instances. We need a host to direct customers to different lines to place their order, managing the distribution of traffic.</p> <p>We apply this to AWS environments as elastic load balancing.</p> <p>Load balancer is application that takes in requests and routes them to different instances to be processed. Many off the shelf solutions that work great with AWS.</p> <p>AWS can provide this service in the form of Elastic Load Balancing. This is an AWS managed service that addresses issue of load balancing.</p> <p>Because it runs at the region level rather than on specific EC2 instances, the service is automatically highly available with no additional effort on your part.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#messaging-and-queueing","title":"Messaging and queueing","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#tightly-coupled-architecture","title":"Tightly-coupled architecture","text":"<p>If a single component has a problem it causes problems for other components or the whole system.</p> <p>Applications made up of tightly coupled components are monolithic.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#loosely-coupled-architecture","title":"Loosely coupled architecture","text":"<p>Single failure won't cause cascading failures.</p> <p>You have a queue in the middle where messages go to eventually be processed. If a given application can't process the message, it stays in the queue until it is processed by another application.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-sqs-amazon-simple-queue-service","title":"Amazon SQS (Amazon Simple Queue Service)","text":"<p>Allows you to send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available.</p> <p>Payload is the data inside the message, and it is protected until delivery.</p> <p>SQS queues are where messages are placed until they are processed.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-sns-amazon-simple-notification-service","title":"Amazon SNS (Amazon Simple Notification Service)","text":"<p>Amazon SNS can send out messages but it can also send out notifications to end users. Uses a publish subscribe model.</p> <p>Can make an Amazon SNS topic: a channel for messages to be delivered. Can then configure subscribers for that topic, and publish messages for subscribers.</p> <p>Subscribers can be web servers, email addresses, AWS Lambda functions, or several other options.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#additional-compute-services","title":"Additional compute services","text":"<p>Though EC2 is good in a lot of cases, depending on your use case you might want an alternative.</p> <p>When using EC2 you are responsible for setting up and managing your instances over time.</p> <p>AWS offers multiple serverless compute options, meaning that you don't see or access the underlying infrastructure tha`t is hosting your application. Instead, all management of the underlying environment is taken care of. All you need to do is focus on your application.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#serverless-computing","title":"Serverless computing","text":"<p>When computing with virtual servers you have to think about the servers and code, while when serverless computing you only have to think about the code.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-lambda","title":"AWS Lambda","text":"<p>AWS Lambda is a serverless compute option. More suited for quick processes, not something like deep learning.</p> <p>Allows you to run code without needing to provision or manage servers. You can run code for virtually any type of application or backend service, all with zero administration.</p> <p>Setup:</p> <ol> <li>Upload code to Lambda</li> <li>Set code to trigger from an event source</li> <li>Code only runs when triggered</li> <li>Pay only for the compute time you use</li> </ol>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-elastic-container-service-amazon-ecs","title":"Amazon Elastic Container Service (Amazon ECS)","text":"<p>Containers provide you with a standard way to package your application's code and dependencies into a single object. Can also use containers for processes and workflows in which there are essential requirements for security, reliability, and scalability.</p> <p>Using containers could delp to ensure that the application's environment remains consistent regardless of deployment.</p> <p>ECS supports Docker containers. With Amazon ECS you can use API calls to launch and stop Docker-enabled applications.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-elastic-kubernetes-service-amazon-eks","title":"Amazon Elastic Kubernetes Service (Amazon EKS)","text":"<p>Amazon EKS is a fully managed service that you can use to run Kubernetes on AWS. Kubernetes is open-source software that enables you to deploy and manage containerized applications at scale.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-fargate","title":"AWS Fargate","text":"<p>Serverless compute engine for containers. Works with both Amazon ECS and Amazon EKS. When using Fargate, you do not need to provision or manage servers. Fargate manages the server infrastructure for you.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/","title":"Global infrastructure and reliability","text":"<p>High availability and fault tolerance is important. AWS operates in many regions to support this.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-global-infrastructure","title":"AWS global infrastructure","text":"<p>Events could happen that could cause lost connection to a certain data center. Most businesses end up just using backups and hoping for no disasters.</p> <p>If disaster strikes, AWS data centers will be fine. They build large data centers in central, business heavy locations.</p> <p>Each of these regions contain multiple data centers that have all the compute, storage, and services you need. Each region is connected to each other region through a high speed fiber network. You get to choose which region you want to run out of. None of your data will come into or out of that region. It is isolated.</p> <p>You might have certain government compliance requirements. E.g., any data in the Frankfurt region never leaves the Frankfurt region, unless you explicitly (with proper credentials) request an export.</p> <p>Proximity and compliance both matters. Latency is always a factor.</p> <p>Sometimes the obvious region choice may not have all of the AWS services/features available. Sometimes brand new services require new hardware and are difficult to implement everywhere.</p> <p>If budget is primary concern, you might want to operate in a different country with different pricing.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#availability-zones","title":"Availability zones","text":"<p>You don't want ot run your business out of a single building, or a single location.</p> <p>AWS has lots of data centers all around the world. Each region is made up of multiple data centers. We refer to these groups of data centers as availability zones (one or more data centers with redundant power, networking, connectivity, etc.).</p> <p>Each region consists of multiple isolated availability zones.</p> <p>As best practice it is recommended that you always run across at least two availability zones in a region, in case one gets taken out.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#edge-locations","title":"Edge locations","text":"<p>What if there is not an obvious answer to the problem of proximity for your business. You can instead cache a copy of your data locally, close to cutomers around the world. This uses concept of Content Delivery Networks (CDNs).</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#amazon-cloudfront","title":"Amazon Cloudfront","text":"<p>Service that helps deliver data, video, applications and APIs to customers around the world with low latency and high transfer speeds. Uses edge locations all around the world to accelerate communications with users no matter where they are.</p> <p>Can push content from a region to a colletion of edge locations around the world to accelerate communication and content delivery.</p> <p>AWS edge locations also run DNS called Amazon Route 53, directing customers to the correct web locations with reliably low latency.</p> <p>AWS Outposts involve basically installing a fully operational mini region right inside your own data center. If you have specific problems that can only be solved by staying within your own building, it would be right for you.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#how-to-provision-aws-resources","title":"How to provision AWS resources","text":"<p>In AWS everything is an API call.</p> <p>You can use tools like:</p> <ul> <li>AWS Management Console</li> <li>AWS Command Line Interface (CLI)</li> <li>AWS Software Development Kits (SDKs)</li> <li>Various other tools</li> </ul> <p>To create requests to send to the AWS APIs to creat and manage AWS resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-management-console","title":"AWS Management console","text":"<p>Browser based, manage visually. Useful for building test environments, AWS bills, view monitoring, and working with non-technical resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-cli","title":"AWS CLI","text":"<p>Allows you to make API calls using the terminal on your machine. Makes actions scriptable and repeatable.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-sdks","title":"AWS SDKs","text":"<p>Allow you to interact through various programming languages.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-elastic-beanstalk","title":"AWS Elastic Beanstalk","text":"<p>Allows you to provision Amazon EC2 based environments. You can just provide your application code and desired configurations to AWS Elastic Beanstalk service, which then takes that info and builds out your environment for you. Can also easily save environment configurations so that they can be deployed again.</p> <p>Gives convenience of not having to provision and manage these things separately, while still giving the visibility and control of underlying resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-cloudformation","title":"AWS Cloudformation","text":"<p>Infrastructure as code tool. Allows you to define wide variety of AWS resources with JSON or YAML text-based documents called cloud-formation templates. Allows you to define what you want to build without specifying exatly how you want to build it.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/","title":"Introduction to Amazon Web Services (AWS)","text":"<ul> <li>Amazon EC2 is a virtual server</li> <li>Client-server model: Client can be a web browser or desktop app that person interacts with, server can be services such as Amazon EC2 (a virtual server)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#deployment-models","title":"Deployment models","text":""},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#cloud-based-deployment","title":"Cloud based deployment","text":"<ul> <li>Run all parts of the application in the cloud</li> <li>Migrate existing applications to the cloud</li> <li>Design and build new applications in the cloud</li> <li>Can build applications on low-level or high-level infrastructure depending on how much management you want to do yourself</li> </ul> <p>Example: Company might create an application consisting of virtual servers, databases, and networking components that are fully based in the cloud</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#on-premises-deployment","title":"On-premises deployment","text":"<ul> <li>Deploy resources by using virtualization and resource management tools</li> <li>Increase resource utilization by using application management and virtualization technologies</li> <li>Also known as private cloud deployment</li> </ul> <p>Example: You might have applications that run on technology that is fully kept in your on-premises data center. Incorporation of application management and virtualization technologies helps to increase resource utilization</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#hybrid-deployment","title":"Hybrid deployment","text":"<ul> <li>Connect cloud-based resources to on-premises infrastructure</li> <li>Integrate cloud-based resources with legacy IT applications</li> </ul> <p>Example: You might have legacy applications that are better maintained on premises, or government regulations require your business to keep certain records on premises. Suppose a company wants to use cloud services that can automate batch data processing and analytics. However, the company has several legacy applications that are more suitable on premises and will not be migrated to the cloud. With hybrid deployment, the company would be able to keep the legacy applications on premises while benefitting from the data and analytics services that run in the cloud.</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#benefits-of-cloud-computing","title":"Benefits of cloud computing","text":""},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#trade-upfront-expense-for-variable-expense","title":"Trade upfront expense for variable expense","text":"<ul> <li>Upfront costs like data centers, physical servers, etc. gone</li> <li>Only pay for resources you consume</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#stop-spending-money-to-run-and-maintain-data-centers","title":"Stop spending money to run and maintain data centers","text":"<ul> <li>Eliminates requirement to spend more money and time managing infrastructure and servers</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#stop-guessing-capacity","title":"Stop guessing capacity","text":"<ul> <li>Don't have to predict how much infrastructure capacity you will need before deploying an application</li> <li>Can deploy Amazon EC2 (Elastic Compute Cloud) when needed, and pay only for the compute time you use</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#benefit-from-massive-economies-of-scale","title":"Benefit from massive economies of scale","text":"<ul> <li>Because lots of customers can aggregate in the cloud, providers, such as AWS, can achieve higher economies of scale (translates to lower prices)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#increase-speed-and-agility","title":"Increase speed and agility","text":"<ul> <li>Flexibility, easier to develop and deploy applications</li> <li>More time to experiment and innovate (access new resources within minutes)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#go-global-in-minutes","title":"Go global in minutes","text":"<p>Deploy applications to customers around the world quickly, while providing them with low latency.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/","title":"Migration and innovation","text":""},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-cloud-adoption-framework-caf","title":"AWS cloud adoption framework (CAF)","text":"<p>Guidance for moving over to cloud.</p> <p>Divides guidance into six perspectives:</p> <ul> <li>Business perspective<ul> <li>Create a business case for cloud adoption</li> </ul> </li> <li>People perspective<ul> <li>Evaluate organizational structures and roles, new skill and process requirements, identify gaps</li> </ul> </li> <li>Governance perspective<ul> <li>Understand how to update the staff skills and processes necessary to ensure business governance in the cloud</li> </ul> </li> <li>Platform perspective<ul> <li>Implementing new solutions on the cloud, migrating on-premises workloads to the cloud</li> </ul> </li> <li>Security perspective<ul> <li>Selection and implementation of security controls that meet the organization's needs</li> </ul> </li> <li>Operations perspective<ul> <li>Enable, run, use, operate, recover IT workloads to level agreed upon with business stakeholders</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#migration","title":"Migration","text":"<p>6 strategies for migration:</p> <ul> <li>Rehosting<ul> <li>Moving applications without changes</li> </ul> </li> <li>Replatforming<ul> <li>Making a few cloud optimizations without changing core application architecture</li> </ul> </li> <li>Refactoring/re-architecting<ul> <li>Reimagining how an application is architected and developed by using cloud-native features</li> <li>Driven by need to add features, scale, performance</li> </ul> </li> <li>Repurchasing<ul> <li>Moving from traditional license to software-as-a-service model</li> <li>Replacing an existing application with a cloud-based version</li> </ul> </li> <li>Retaining<ul> <li>Keeping applications that are critical for the business in the source environment</li> </ul> </li> <li>Retiring<ul> <li>Removing applications that are no longer needed</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snow-family","title":"AWS snow family","text":"<p>Collection of physical devices that help to physically transport up to exabytes of data into and out of AWS.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snowcone","title":"AWS Snowcone","text":"<p>Small, rugged, and secure edge computing and data transfer device. 2 CPUs, 4 GB of memory, 14 TB of usable storage.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snowball","title":"AWS Snowball","text":"<p>Snowball edge storage optimized devices well suited for large-scale data migrations and recurring transfer worklows, local computing higher capacity needs.</p> <p>Snowball edge compute optimized provides powerful computing resources for use cases like ML.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snowmobile","title":"AWS Snowmobile","text":"<p>Exabyte-scale data transfer service used to move large amounts of data to AWS.</p> <p>Up to 100 petabytes of data per Snowmobile, 45-foot long ruggedized shipping container, pulled by a semi trailer truck.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#innovation-with-aws","title":"Innovation with AWS","text":"<p>Focus on desired outcomes: current state, desired state, and problems you are trying to solve.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#serverless-applications","title":"Serverless applications","text":"<p>Don't require you to provision, maintain, or administer servers. AWS Lambda is example.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#artificial-intelligence","title":"Artificial intelligence","text":"<p>For example:</p> <ul> <li>Convert speech to text with Amazon Transcribe</li> <li>Discover patterns in text with Amazon Comprehend</li> <li>Identify potentially fraudulent online activities with Amazon Fraud Detector</li> <li>Build voice and text chatbots with Amazon Lex</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#machine-learning","title":"Machine learning","text":"<p>Amazon SageMaker to remove difficult work from process and empower you to build, train, and deploy ML models quickly.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#amazon-q-developer","title":"Amazon Q Developer","text":"<p>ML code generator. Analyzes, generates comments. Automatically generates suggestions. Can be used as IDE extension.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/","title":"Monitoring and analytics","text":""},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/#aws-cloudwatch","title":"AWS CloudWatch","text":"<p>Monitor and manage various metrics, configure alarms based on those metrics. Can send notifications when alarms are triggered.</p> <p>Has a dashboard feature where you can see all your metrics. Dashboards can also be customized.</p>"},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/#aws-cloudtrail","title":"AWS CloudTrail","text":"<p>Records all API calls for your account, meaning that you always have a record of anything that has happened.</p> <p>Also has \"insights\" feature allowing it to automatically detect unusual API activities in your account.</p>"},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/#aws-trusted-advisor","title":"AWS Trusted Advisor","text":"<p>Checks everything about your AWS setup and gives you recommendations for changes, etc.</p> <p>Green check means no problems, orange triangle means you should investigate, and red circle means you should make a change.</p> <p>Considers: cost optimization, performance, security, fault tolerance, service limits. </p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/","title":"Networking","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-virtual-private-cloud-vpcs","title":"Amazon Virtual Private Cloud (VPCs)","text":"<p>A VPC lets you provision a logically isolated section of the AWS cloud where you can launch AWS resources in a virtual network that you define.</p> <p>The private and public grouping of resources are known as subnets, and they are ranges of IP addresses in your VPCs.</p> <p>Essentially your own private network in AWS. Allows you to define your private IP range for your AWS resources, and you place things like EC2 instances and ELBs (Elastic Load Balancers) inside of your VPC.</p> <p>For some VPCs you might have internet-facing resources that the public should be able to reach, like a public website. In other scenarios you might have resources that you only want to be reachable if someone is logged into your private network, such as an HR application or backend database.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#internet-gateway-igw","title":"internet gateway (IGW)","text":"<p>In order to allow traffic from the public internet to flow into and out of your VPC, you must attach what is called an internet gateway, or IGW, to your VPC. This is like a doorway that is open to the public.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#virtual-private-gateway","title":"Virtual private gateway","text":"<p>If we don't want just anyone to be able to access these resources, we want a private gateway that only lets in people coming from an approved network.</p> <p>This is called a virtual private gateway, and allows you to create a VPN connection between a private network (like your on-premises data center) and your VPC.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#direct-connect","title":"Direct connect","text":"<p>The problem with using a VPN connection is they use bandwidth being shared by many people using the internet. To get around this you can use AWS direct connect, which allows you to establish a completely private, dedicated fiber connection from your data center to AWS. This can help with high regulatory and compliance needs, as well as any bandwidth issues.</p> <p>One VPC might have multiple types of gateways attached for multiple types of resources all residing in the same VPC, just in different subnets.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#subnets-and-network-access-control-lists","title":"Subnets and network access control lists","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#subnets","title":"Subnets","text":"<p>Public subnets contain resources that need to be accessible by the public, such as an online store's website.</p> <p>Private subnets contain resources that should be accessible only through your private network, such as a database that contains customers' personal information and order histories.</p> <p>Internet gateways only cover the perimeter. We need to cover other layers of security as well.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#network-hardening","title":"Network hardening","text":"<p>The only technical reason to use subnets in a VPC is to control access to gateways. Subnets can also control packet permissons. Every packet that tried to cross over the subnet boundary gets checked against the network access control list (network ACL). This is to see if the packet has permissions to leave or enter the subnet. Network ACL kinda acts like a border control officer.</p> <p>By default, your AWS account's network access control list is stateless and allows all inbound and outbound traffic.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#security-groups","title":"Security groups","text":"<p>This does not solve the problem of different levels of security for different EC2 instances within the subnet though. You need instance-level security as well. For this we can use security groups. You can modify these groups to accept specific types of traffic. These are like a doorman at a building or hotel. You may been let into the country by the border control officer, but the doorman of the building might turn you away.</p> <p>By default, security groups allow any traffic out and deny all incoming traffic. Key difference between network ACL and security group is a security group is stateful, meaning that it remembers what to let in or out. A network ACL checks every packet regardless.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#global-networking","title":"Global networking","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-route-53","title":"Amazon Route 53","text":"<p>Highly available and scalable DNS. Think of it as a translation service, but instead of translating languages, it translates website names into IP addresses.</p> <p>Some of the route 53 routing policies:</p> <ul> <li>Latency based</li> <li>Geolocation DNS<ul> <li>Direct traffic based on where customer is located</li> </ul> </li> <li>Geoproximity</li> <li>Weighted round robin</li> </ul> <p>You can also use route 53 to buy and manage domain names.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-cloudfront","title":"Amazon Cloudfront","text":"<p>Using edge locations with cached content to better serve content around the world using CDNs. A CDN is a network that delivers edge content to users based on their geographic location.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/","title":"Pricing and support","text":""},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-free-tier","title":"AWS Free Tier","text":"<p>Has always free, 12 months free, and trial options.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-pricing-concepts","title":"AWS Pricing Concepts","text":"<p>Pay for what you use. Pay less when you reserve. Pay less when you use more.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-pricing-calculator","title":"AWS Pricing Calculator","text":"<p>Get estimates for different AWS services. Can organize them by groups (a group could represent one of your cost centers, for example).</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-lambda-pricing","title":"AWS Lambda Pricing","text":"<p>Charged based on number of requests for your functions and time it takes them to run. 1 mill free requests, 3.2 million seconds of compute time per month.</p> <p>Compute Savings Plan: lower costs, commit to consistent usage over 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#amazon-ec2-pricing","title":"Amazon EC2 Pricing","text":"<p>Pay only for compute time you use.</p> <p>Can significantly reduce costs using Spot instances.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#amazon-s3-pricing","title":"Amazon S3 Pricing","text":"<p>Cost components:</p> <ul> <li>Storage</li> <li>Requests and data retrievals</li> <li>Data transfer</li> <li>Management and replication</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-billing-dashboard","title":"AWS billing dashboard","text":"<ul> <li>Compare current balance with previous month, get forecast based on usage</li> <li>View spending by service</li> <li>View free tier usage by service</li> <li>Cost explorer, create budgets</li> <li>Purchase and manage savings plans</li> <li>AWS cost and usage reports</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#consolidated-billing","title":"Consolidated billing","text":"<p>Receive single bill for all accounts in your organization (up to 4 by default).</p> <p>Can review itemized charges on each account.</p> <p>Can share bulk idscount pricing.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-budgets","title":"AWS budgets","text":"<p>Create budgets to plan service usage, costs, instance reservations.</p> <p>Info updates three times a day to help determine whether meeting budget.</p> <p>Get notified when usage exceeds.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-cost-explorer","title":"AWS cost explorer","text":"<p>Visualize, understand, manage AWS costs and usage.</p> <p>Custom filters and groups.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-support","title":"AWS support","text":"<p>Support plans:</p> <ul> <li>Basic</li> <li>Developer</li> <li>Business</li> <li>Enterprise on-ramp</li> <li>Enterprise</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#basic-support","title":"Basic support","text":"<p>Free for all customers. Whitepapers, documentation, support communities. Can contact AWS for billing questions and service limit increases.</p> <p>Limited selection of AWS trusted advisor checks.</p> <p>AWS personal health dashboard: provides alerts and guidance when AWS is experiencing events affecting you.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#developer-business-enterprise-on-ramp-enterprise-support","title":"Developer, business, enterprise on-ramp, enterprise support","text":"<p>Additional ability to open unrestricted number of technical support cases. Pay-by-month, no long-term contracts.</p> <p>From lowest to highest cost: Developer, business and enterprise on-ramp, enterprise.</p> <p>Only business, enterprise on-ramp, and enterprise support include all trusted advisor checks.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#technical-account-manager-tam","title":"Technical account manager (TAM)","text":"<p>Only available to enterprise on-ramp and enterprise support plans.</p> <p>Primary point of contact.</p> <p>Helps across all AWS services.</p> <p>Expert engineering guidance.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-marketplace","title":"AWS marketplace","text":"<p>Digital catalog including thousands of software listings from independent software vendors. Find, test, and buy software that runs on AWS.</p> <p>Explore by industry and use case.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/security/","title":"Security","text":""},{"location":"aws-cloud-practitioner-essentials/security/#shared-responsibility-model","title":"Shared responsibility model","text":"<p>AWS controls security of the cloud, while customers control security in the cloud.</p> <p>Consider a homeowner and a homebuilder. The builder (AWS) is responsible for constructing your house and ensuring that it is solidly built. As the homeowner (the customer), it is your responsibility to secure everything in the house by ensuring that the doors are closed and locked.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#user-permissions-and-access","title":"User permissions and access","text":"<p>AWS root user: Access and control any part of the account. You do not want to use the root user for everything of course.</p> <p>You can control access in a granular way using AWS Identity and Access Management (AWS IAM). You can use this to create IAM users that by default do not have any permissions.</p> <p>You have to explicitly give IAM users permissions to do anything in that account. Following the principle of least privilige, you only give users access to what they need.</p> <p>An IAM policy is a JSON document describing what API calls a user can or cannot make.</p> <p>One way to make it easier to manage your users and their permissions is to organize them into IAM groups. Groups are groupings of user policies.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#roles","title":"Roles","text":"<p>Roles have associated permissions that can allow or deny certain actions, and can be assumed for temporary amounts of time.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-organizations","title":"AWS Organizations","text":"<p>AWS Organizations is a central location to manage multiple AWS accounts. Also has consolidated billing. Can also implement hierarchical groupings of accounts. Also have control over the AWS service and API actions access control.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#service-control-policies-scps","title":"Service control policies (SCPs)","text":"<p>Enable you to place restrictions on the AWS services, resources, and individual API actions that users and roles in each account can access.</p> <p>SCPs can be applied to organizational units and individual member accounts.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#compliance","title":"Compliance","text":"<p>AWS complies with a long list of assurance programs.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-artifact","title":"AWS Artifact","text":"<p>Gain access to compliance reports completed by third parties.</p> <p>Suppose your company needs to sign an agreeement with AWS regarding your use of certain types of information throughout AWS services. You can do this through AWS Artifact Agreements.</p> <p>Next, suppose a member of your company's development team is building an application and needs more information about their responsibility for complying with certain regulatory standards. You can advice them to access this information in AWS Artifact Reports.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#denial-of-service-attacks","title":"Denial-of-service attacks","text":"<p>Objective of DDoS attack is to shut down system by overwhelming it. Leverages other machines to unknowingly attacking your infrastructure. Key to a powerful attack if if the attacker creates the most work possible for the infrastructure while putting in the least amount of effort possible.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#udp-flood","title":"UDP flood","text":"<p>Example is asking the weather service to send a bunch of information to a return address (the return address of the service you are trying to cripple) to overload it without it asking for that info.</p> <p>Solution: Security groups that only allow in proper request traffic that we want.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#http-level-attacks","title":"HTTP level attacks","text":"<p>Look like normal customers asking for normal things, but repeated over and over by bot machines.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#slowloris-attack","title":"Slowloris Attack","text":"<p>Attacker pretends to have a terribly slow connection, meanwhile until their request finishes you can't move on to the next one.</p> <p>Solution: Elastic load balancer. To overwhelm ELB you would have to overwhlem the entire AWS region.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-shield-with-aws-waf","title":"AWS Shield with AWS WAF","text":"<p>WAF uses a web application firewall to filter incoming traffic.</p> <p>AWS Shield Standard automatically protects all AWS customers at no cost. It protects your AWS resources from the most common, frequently ocurring types of DDoS attacks.</p> <p>AWS Shield Advanced is a paid service that provides detailed attack diagnostics and the ability to detect and mitigate sophisticated DDoS attacks.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#additional-security-services","title":"Additional security services","text":""},{"location":"aws-cloud-practitioner-essentials/security/#aws-key-management-service-aws-kms","title":"AWS key management service (AWS KMS)","text":"<p>Enables you to perform envryption operations through the use of cryptographic keys. A cryptographic key is a random string of digits used for locking (encrypting) and unlocking (decrypting) data. Can use AWS KMS to create, manage, and use cryptographic keys.</p> <p>Can choose specific levels of access control you need for your keys.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-waf","title":"AWS WAF","text":"<p>Web application firewall that lets you monitor network requests that come into your web applications.</p> <p>Works together with CloudfFront and Application Load Balancer.</p> <p>Uses a web access control list (ACL) to protect your AWS resources.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#amazon-inspector","title":"Amazon inspector","text":"<p>Can perform automated security assessments, and returns a list of security findings.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#amazon-guardduty","title":"Amazon GUardDuty","text":"<p>Provides intelligent threat detection for your AWS infrastructure and resources. Identifies threats by continuously monitoring the network activity and account behavior within your AWS environment.</p> <p>GuardDuty findings can be reviewed in the AWS management console.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/","title":"Storage and databases","text":"<p>As EC2 instances run applications, those applications will often require block-level storage. In block level storage, when something is changed only that aspect is rewritten rather than the entire thing. This makes it an efficient storage type when working with databases, enterprise software or file systems.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#instance-stores-and-amazon-elastic-block-store-amazon-ebs","title":"Instance stores and amazon elastic block store (Amazon EBS)","text":""},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#instance-store-volumes","title":"Instance store volumes","text":"<p>When you launch an EC2 instance it might provide you with local storage called instance store volumes. These are physically attached to the host your EC2 instance is running on top of. You can write to it just like a normal hard drive. The problem here is that if you terminate the instance or host, all data in the instance store volumes will be deleted. This is because you often start up an instance on a different host.</p> <p>So these are useful in situations where you can afford to lose the data being written to the drives.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-elastic-block-store-amazon-ebs","title":"Amazon elastic block store (Amazon EBS)","text":"<p>If you do not want to be losing your database every time your instance is terminated, you can use Amazon EBS. This allows you to create virtual hard drives that are not attached to the host the EC2 instance is running on. The data persists through stops and starts of an instance.</p> <p>EBS allows you to create incremental backups of your database called snapshots.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-simple-storage-service","title":"Amazon simple storage service","text":"<p>Store and retrieve an unlimited amount of data. Store data as objects, in buckets.</p> <p>in object storage, each object consists of data, metadata, and a key.</p> <p>Maximum object size of 5 TB. Can version objects, and create multiple buckets.</p> <p>Another way to use S3 is static website hosting (a bunch of static HTML files).</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-s3-standard-infrequent-access-s3-standard-ia","title":"Amazon S3 standard-infrequent access (S3 Standard-IA)","text":"<p>Used for data accessed less frequently, requires rapid access when needed. Good place to store backups, disaster recovery files, etc.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-s3-glacier-flexible-retrieval","title":"Amazon S3 Glacier Flexible Retrieval","text":"<p>Good for retaining data for several years for auditing purposes. Can either move data to it or use vaults populated with archives. Can use a S3 Glacier Vault lock policy to meet compliance requirements (can use policies like write once/read many WORM).</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-s3-glacier-deep-archive","title":"Amazon S3 Glacier Deep Archive","text":"<p>Good for archival data.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#lifecycle-policies","title":"Lifecycle policies","text":"<p>Policies that automatically move data between tiers. For example, keeping an object in S3 standard for 90 days then moving it to S3 standard IA for 30 days, and so on...</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#comparing-amazon-ebs-and-amazon-s3","title":"Comparing Amazon EBS and Amazon S3","text":""},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-ebs","title":"Amazon EBS","text":"<ul> <li>Sizes up to 16 TiB</li> <li>Survive termination of their EC2 instance</li> <li>Solid state by default</li> <li>HDD options</li> </ul> <p>An EBS volume must be located in the same Availability Zone as the Amazon EC2 instance to which it is attached.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-simple-storage-service-s3","title":"Amazon Simple Storage Service (S3)","text":"<ul> <li>Unlimited storage</li> <li>Individual objects up to 5 TBs</li> <li>Write once/read many</li> <li>99.999999999% durability</li> </ul> <p>Difference between object storage and block storage: Object storage treats any file as a complete, discrete object. Great for documents, images, and video files that get uploaded and consumed as entire objects. However, any time a change happens you must re-upload the entire file. Block storage breaks those files down into component parts, meaning that when you make an edit to one part, the edit only updates the blocks where those bits live.</p> <p>If you are using only complete objects, S3 is victorious. If you are doing complex read/write change functions, then EBS is better.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-elastic-file-system-amazon-efs","title":"Amazon Elastic File System (Amazon EFS)","text":"<p>Managed file system. Common for businesses to have shared file systems across their applications. Might have multiple servers running analytics on data stored in a shared file system. With EFS you can leave the file system in place and let AWS handle all the scaling and replication.</p> <p>EFS allows you to have multiple instances that can access the data in EFS at the same time. Scales up and down as needed.</p> <p>Data in an Amazon EFS file system can be accessed concurrently from all the Availability Zones in the Region where the file system is located.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#what-is-the-difference-between-ebs-and-efs","title":"What is the difference between EBS and EFS?","text":"<p>EBS volumes attach to EC2 instances and are an availability zone level resource. In order to attach EC2 to EBS you need to be in the same AZ. Volumes also do not automatically scale to give you more storage.</p> <p>EFS can have multiple instances reading and writing simultaneously. It is a true Linux file system, and a regional resource. So any EC2 instance in the region can write to the EFS. Also automatically scales.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-relational-database-services","title":"Amazon relational database services","text":"<p>If you want to keep track of relationships between different data, you should use a relational database management system (RDBMS).</p> <p>AWS supports multiple databases like MySQL, PostgreSQL, Oracle, and Microsoft SQL Server.</p> <p>To migrate your databases to AWS you can perform a lift and shift to an EC2 instance.</p> <p>You can also use a more managed service like Amazon Relational Database Service (Amazon RDS). Comes with automated patching, backups, redundancy, failover, disaster recovery, etc.</p> <p>Amazon Aurora is another option that is even more managed. Comes in MySQL and PostgreSQL, and comes in at 1/10th the cost of commercial databases. Data is replicated across facilities, and you can upload up to 15 read replicas. There are also continuous backups to S3, so you always have a backup ready to restore.</p> <p>Amazon Aurora is considered to be part of Amazon RDS.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-dynamodb","title":"Amazon DynamoDB","text":"<p>At its most basic level it is a serverless database. You don't need to manage the underlying instances or infrastructure powering it. You can create tables populated with items that have attributes. The burden of operating an available database is much lower when using DynamoDB.</p> <p>Does not use SQL. Rigid SQL databases can have performance and scaling issues when under stress. Might not be best for dataset that is not rigid and might be accessed at a very high rate.</p> <p>DynamoDB is a non-relational database. You can add and remove attributes from items in a table anytime, and not every item in a table has to have the same attributes. You write queries based on a small subset of attributes designated as keys. Queries of this type generally focus on a collection of items from one table rather than across multiple tables. Allows it to be quick and scalable.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#comparing-amazon-rds-and-amazon-dynamodb","title":"Comparing Amazon RDS and Amazon DynamoDB","text":""},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-rds","title":"Amazon RDS","text":"<ul> <li>Automatic high availability; recovery provided</li> <li>Customer ownership of data</li> <li>Customer ownership of schema</li> <li>Customer control of network</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-dynamodb_1","title":"Amazon DynamoDB","text":"<ul> <li>Key-value</li> <li>NoSQL</li> <li>Massive throughput capabilities</li> <li>PB size potential</li> <li>Granular API access</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#which-one-is-right-for-you","title":"Which one is right for you?","text":"<p>If you need complex relational joins between tables, you need RDS. For pretty much anything else, you could use DynamoDB. If you basically just need lookup tables (single table stuff), DynamoDB would be great.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-redshift","title":"Amazon Redshift","text":"<p>Once data becomes too complex to handle with traditional relational databases, you've entered the world of data warehouses. Good for historical analytics. As long as your data question involves looking backward, then a data warehouse could be right for that situation.</p> <p>Amazon Redshift is data warehousing as a service, and is massively scalable. Can achieve much better performance compared to other database technologies for these kinds of queries. When you need big data business intelligence solutions, Redshift is a good choice.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#aws-data-migration-service","title":"AWS Data Migration Service","text":"<p>Does AWS have a magical way to help you migrate your existing database?</p> <p>Essentially migrate data between a source database and target database, with the source database remaining fully operational during the migration. The source and target databases don't even have to be the same type.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#homogeneous-databases","title":"Homogeneous databases","text":"<p>Migration between two databases of same type. The source database could be on premises running on EC2 instances, or can be an Amazon RDS database. The target database can be Amazon EC2, or Amazon RDS.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#heterogeneous-migration","title":"Heterogeneous migration","text":"<p>When the source and target are of different types. 2-step process, uses conversion tool to match the schema and database code, then you migrate it.</p> <p>Other use cases:</p> <ul> <li>Development and test database migrations<ul> <li>When you want your developers to test against production data but without affecting production users, so you create a copy</li> </ul> </li> <li>Database consolidation<ul> <li>When you have several databases and want to combine them into one</li> </ul> </li> <li>Continuous replication<ul> <li>When you use DMS to perform continuous database replication (disaster recovery, or geographic separation)</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#additional-database-services","title":"Additional database services","text":"<p>What if you need a full content management system?</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-documentdb-mongodb-compatability","title":"Amazon DocumentDB (MongoDB compatability)","text":"<p>Content management, catalogs, user profiles, etc.</p> <p>What if you had a social network and wanted to see who is connected to who etc.?</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-neptune","title":"Amazon Neptune","text":"<p>Graph database engineered for social networking. Also great for fraud detection needs. Or tracking a supply chain, or banking records requiring 100% immutability.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-managed-blockchain","title":"Amazon Managed Blockchain","text":"<p>Blockchain solution.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-quantum-ledger-database","title":"Amazon Quantum Ledger Database","text":"<p>immutable records where any entry can never be removed from the audits.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#database-accelerators","title":"Database accelerators","text":"<p>Caching layers that can hlp improve the read times of common requests.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-elasticache","title":"Amazon ElastiCache","text":"<p>Caching layers without heavy lifting.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-dynamodb-accelerator","title":"Amazon DynamoDB Accelerator","text":"<p>An in-memory cache for DynamoDB.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/well-architected-framework/","title":"Well-architected framework","text":"<p>Helps you understand how to best design and operate your AWS cloud system.</p> <p>Based on six pillars:</p> <ul> <li>Operational excellence<ul> <li>Ability to run and monitor systems to deliver business value and to continually improve supporting processes and procedures</li> </ul> </li> <li>Security<ul> <li>Ability to protect information, systems, and assets while delivering business value through risk assessments and mitigation strategies</li> </ul> </li> <li>Reliability<ul> <li>Ability of a system to recover from disruptions, dynamically acquire resources, mitigate disruptions, etc.</li> </ul> </li> <li>Performance efficiency<ul> <li>Ability to use computing resources efficiently to meet system requirements and to maintain that efficiency</li> </ul> </li> <li>Cost optimization<ul> <li>Ability to run systems to deliver business value at lowest price point</li> </ul> </li> <li>Sustainability<ul> <li>Ability to continually improve sustainability impacts by reducing energy consumption and increasing efficiency across all components of a workload by maximizing the benefits from the provisioned resources and minimizing the total resources required</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/well-architected-framework/#benefits-of-aws-cloud","title":"Benefits of AWS cloud","text":"<p>Advantages of cloud computing:</p> <ul> <li>Trade upfront expense for variable expense</li> <li>Benefit from massive economies of scale</li> <li>Stop guessing capacity</li> <li>Increase speed and agility</li> <li>Stop spending money running and maintaining data centers</li> <li>Go global in minutes</li> </ul> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/","title":"Where in the genome does DNA replication begin?","text":"<p>Replication begind in a genomic region called the replication origin (denoted \\(oriC\\)).</p> <p>In the context of gene therapy it is important to figure out where the \\(oriC\\) is within the genome so that it can be preserved. This is because it is necessary for gene replication, which is an important part of gene therapy.</p> <p>Research has shown that the region of the bacterial genome encoding \\(oriC\\) is typically a few hundred nucleotides long.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#finding-the-oric","title":"Finding the \\(oriC\\)","text":"<p>One way we can try to find the \\(oriC\\) is by looking for the \\(DnaA\\) box, a DNA sequence that is essentially a message telling the \\(DnaA\\) protein: \"bind here!\"</p> <p>We want to look for something that stands out in \\(oriC\\), in other words, some sort of pattern.</p> <p>One way we can define this problem is as a pattern counting problem, where we search for the most frequent \\(k\\)-mers, or, strings of length \\(k\\).</p> <p>We can use the following algorithm:</p> <pre><code>def pattern_count(text, pattern):\n    count = 0\n    for i in range(0, len(text)-len(pattern)):\n        if text[i:(i+len(pattern))] == pattern:\n            count += 1\n    return count\n</code></pre>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#the-frequent-words-problem","title":"The Frequent Words problem","text":"<p>Let us extend this further. We can generalize to wanting to find the most frequent \\(k\\)-mer for all values of \\(k\\) possible for the text.</p> <p>We say that \\(Pattern\\) is a most frequent \\(k\\)-mer in \\(Text\\) if it mazimizes <code>pattern_count(text, pattern)</code> among all \\(k\\)-mers.</p> <p>So our problem is as follows:</p> <p>Input: A string \\(Text\\) and an integer \\(k\\)</p> <p>Output: All most frequent \\(k\\)-mers in \\(Text\\)</p> <p>There will be \\(|Text|-k+1\\) \\(k\\)-mers to check in a given string \\(Text\\).</p> <p>To implement this algorithm <code>frequent_words</code> we need to store an array <code>count</code> containing the number of occurrences of each pattern \\(Pattern = Text(i,k)\\), where <code>count[i]</code> stores <code>count(text, pattern)</code> for \\(Pattern = Text(i,k)\\). So if we have a pattern of length 3, <code>count[2]</code> would be the number of occurrences of the substring from index 2 to index (2 + 3) - 1 = 4.</p> <p>Here is the algorithm:</p> <pre><code>def frequent_words(text, k):\n    count = []\n    frequent_patterns = []\n    max_count = 0\n    for i in range(0, len(text)-k):\n        pattern = text[i:(i+k)]\n        count.append(pattern_count(text, pattern))\n        if count[i] &gt; max_count:\n            max_count = count[i]\n    for i in range(0, len(text)-k):\n        if count[i] == max_count:\n            frequent_patterns.append(text[i:(i+k)])\n    frequent_patterns = list(dict.fromkeys(frequent_patterns))\n    return frequent_patterns\n</code></pre> <p>This works, but it is not very efficient.</p> <p>Each \\(k\\)-mer requires \\(|Text| - k + 1\\) checks, each requiring as many as \\(k\\) comparisons, so overall # of steps of <code>pattern_count(text, pattern)</code> is \\((|Text| - k + 1) \\cdot k\\).</p> <p>Additionally, <code>frequent_words</code> must call <code>pattern_count</code> \\(|Text| - k + 1\\) times (once for each \\(k\\)-mer of \\(Text\\)), so its overall number of steps is \\((|Text| - k + 1) \\cdot (|Text| - k + 1) \\cdot k\\).</p> <p>To simplify, its complexity is \\(\\mathcal{O}(|Text|^2\\cdot k)\\).</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#another-way-of-doing-this","title":"Another way of doing this","text":"<p>With the goal of making our algorithm more efficient, we can address the main issue: we look through the entire string for every different \\(k\\)-mer pattern. Our new idea is to pass through the string once for each \\(k\\), maintaining a count of each possible \\(k\\)-mer and adding to each \\(k\\)-mer's count whenever we pass over it. Since these strings are made up of four different possible characters, we will have \\(4^k\\) possible \\(k\\)-mers for each value of \\(k\\).</p> <p>We define the frequency array of a string \\(Text\\) as an array of length \\(4^k\\), where the \\(i\\)-th element of the array holds the number of times that the \\(i\\)-th \\(k\\)-mer (in the lexographic order) appears in \\(Text\\).</p> <p>To make this work we need to be able to transform strings to integers and back to strings. We can figure out the possible \\(k\\)-mers, order them lexographically, then number them based on that ordering. Based on that numbering we can encode our string as an integer, where each \\(k\\)-mer is described by its number in the lexographic ordering.</p> <p>The following algorithms are for encoding and decoding out representations:</p> <p>Encoding:</p> <pre><code>def pattern_to_number(pattern):\n    if not pattern:\n        return 0\n    symbol_to_number = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n    result = 0\n    for char in pattern:\n        result = result * 4 + symbol_to_number[char]\n    return result\n</code></pre> <p>Decoding:</p> <pre><code>def number_to_pattern(index, k):\n    if k == 0:\n        return \"\"\n    number_to_symbol = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n    prefix_index = index // 4\n    remainder = index % 4\n    symbol = number_to_symbol[remainder]\n    if k == 1:\n        return symbol\n    else:\n        prefix_pattern = number_to_pattern(prefix_index, k-1)\n        return prefix_pattern + symbol\n</code></pre> <p>We can now move on to the problem of generating frequency arrays. We can first initialize every \\(4^k\\) elements in the frequency array to zero, then make a single pass down the string. For each \\(k\\)-mer we encounter, we add 1 to the value of the frequency array corresponding to it.</p> <p>If working in Python we can use a dict for our frequency array:</p> <pre><code>def frequency_array(k):\n    frequencies = {}\n    for i in range(0, (4**k)):\n        frequencies[number_to_pattern(i, k)] = 0\n    return frequencies\n</code></pre> <p>This uses our previously built <code>number_to_pattern</code> function to populate our dictionary with keys corresponding to each possible \\(k\\)-mer, in lexicographical order.</p> <p>We can now put it all together with a complete algorithm that is faster than our original solution:</p> <pre><code>def faster_frequent_words(text, k):\n    frequencies = frequency_array(k)\n    for i in range(len(text) - k + 1):\n        frequencies[text[i:i+k]] += 1\n    max_value = max(frequencies.values())\n    print(frequencies)\n    return [key for key, value in frequencies.items() if value == max_value]\n</code></pre> <p>This algorithm initializes a dict of all possible \\(k\\)-mers. It then iterates through \\(Text\\) and adds each \\(k\\)-mer occurrence to the frequency dict. We then get the maximum value of the frequency dict, and iterate through the frequency dict to check for strings that match that maximum value. Strings that have occurrences equal to the max are returned. </p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#references","title":"References","text":"<p>Compeau, P., &amp; Pevzner, P. (2015). Bioinformatics algorithms: An active learning approach (Vol. 1). Active Learning Publishers.</p>"},{"location":"linux-essentials/linux-administration/utility-commands-user-management/","title":"Utility commands and user management","text":""},{"location":"linux-essentials/linux-administration/utility-commands-user-management/#linux-file-editor","title":"Linux file editor","text":"<p>Several standard text editors on most Linux systems:</p> <ul> <li><code>vi</code> visual editor</li> <li><code>ed</code> standard line editor</li> <li><code>ex</code> extended line editor</li> <li><code>emacs</code> a full screen editor</li> <li><code>pico</code> beginner's editor</li> <li><code>vim</code> advanced version of vi</li> </ul> <p>Will focus on <code>vi</code> because it is usually available on every Linux system and is easy to learn.</p>"},{"location":"linux-essentials/linux-administration/utility-commands-user-management/#most-common-vi-commands","title":"Most common <code>vi</code> commands","text":"<p><code>i</code> insert <code>Esc</code> escape out of any mode <code>r</code> replace <code>d</code> delete <code>:q!</code> quit without saving <code>:wq!</code> quit and save</p> <p>When you enter <code>vi</code> you will be in command mode. The other mode is the typing (insert) mode.</p> <p>To enter typing mode you hit <code>i</code> or \"insert\".</p> <p>To save you could shift + z z. Or you could do <code>:wq!</code></p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/","title":"Commands and permissions","text":"<p>Commands syntax:</p> <pre><code>command option(s) argument(s)\n</code></pre>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#options","title":"Options","text":"<p>Options modify the way a command works, and usually consist of a dash followed by a single letter.</p> <p>Multiple options can be grouped together after a single hyphen.</p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#arguments","title":"Arguments","text":"<p>Most commands are used with one or more arguments.</p> <p>Some commands assume a default argument if none is supplied.</p> <p>Arguments are optional for some commands and required by others.</p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#useful-commands","title":"Useful commands","text":"<p><code>whoami</code> to determine which user you are.</p> <p><code>pwd</code> to display your directory.</p> <p><code>cd</code> to move about directories.</p> <p><code>ls</code> to see items within working directory.</p> <p><code>cp</code> to copy a file from one directory to another.</p> <ul> <li>The third column in file info tells you the owner of the file.</li> <li>The fourth column is the group name for that file.</li> <li>Fifth column gives number of bytes for the file.</li> <li><code>ll</code> gives same result as <code>ls -l</code></li> </ul> <p><code>rm -f</code> to delete a file without confirming, <code>rm -r</code> to delete a directory.</p> <p><code>mkdir</code> to create a directory.</p> <p><code>man</code> with a command as argument to see man page for a command.</p> <p><code>date</code> gives the date on your system.</p> <p><code>more</code> gives output one page at a time. Piping with more is useful.</p> <p><code>tail</code> gives last line of an output. Also useful in piping.</p> <p><code>cat</code> reads contents of a file.</p> <p>To become a super user (root user) use <code>sm -</code> and enter your password.</p> <ul> <li>To leave root user account: <code>exit</code></li> </ul>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#permissions","title":"Permissions","text":"<p><code>r</code> - read <code>w</code> - write <code>x</code> - execute = running a program</p> <p>Each permission can be controlled at three different levels:</p> <p><code>u</code> - user <code>g</code> - group <code>o</code> - other = everyone on the system</p> <p>To see file or directory permissions run <code>ls -l</code>:</p> <p>Example: <code>-rwxrwxrwx</code></p> <p>First bit indicates a file, next three bits are user permissions, then next three are group, and last three are permissions for others.</p> <p><code>chmod</code> can be used to change permissions.</p> <p>Example: Removing group write permissions from file <code>testfile</code>: <code>chmod g-w testfile</code> Example: Removing write permissions for everyone from file <code>testfile</code>: <code>chmod a-w testfile</code></p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#file-ownership","title":"File ownership","text":"<p><code>chown</code> changes the ownership of a file.</p> <p>Example: To change the ownership from a user to root: <code>chown root testfile</code></p> <p><code>chgrp</code> changes the group ownership of a file.</p> <p>The <code>-R</code> option changes ownership recursively (everything within will also have ownership changed).</p> <p>Note: If a file you do not have ownership of is within a directory that you have permissions for, you can still delete/make changes to it. For this reason is it often important to perform recursive ownership changes to ensure they are properly applied for your case.</p> <p>Source: Linux for Absolute Beginners: Commands and Permissions by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/file-commands/","title":"File commands","text":""},{"location":"linux-essentials/linux-command-line/file-commands/#file-display-commands","title":"File display commands","text":"<ul> <li><code>cat</code> views entire content</li> <li><code>more</code> views one page at a time</li> <li><code>less</code> views content in reverse order, one page at time</li> <li><code>head</code> gives the first few lines</li> <li><code>tail</code> gets you the last lines of a file</li> </ul>"},{"location":"linux-essentials/linux-command-line/file-commands/#file-maintenance-commands","title":"File maintenance commands","text":"<ul> <li><code>cp</code> copies a file from one location to another</li> <li><code>rm</code> removes a file</li> <li><code>mv</code> used to move location of file from one to another, or rename it</li> <li><code>mkdir</code> makes a directoy</li> <li><code>rmdir</code> or <code>rm -r</code> removes directory</li> <li><code>chgrp</code> changes group ownership</li> <li><code>chown</code> changes ownership</li> </ul> <p>Source: Linux for Absolute Beginners: File Commands and Filters by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/","title":"File comparison and splitting","text":""},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#cut-command","title":"Cut command","text":"<p>Cut is a command utility that allows you to cut parts of lines from specific files or piped data and print the result to standard output.</p> <p>Can be used to cut parts1 of a line by a delimiter, byte position, and character.</p> <p><code>cat -c1 filename</code> list one character <code>cut -c1,2,4</code> pick and choose character(s) <code>cut -c1-3 filename</code> list range of characters <code>cut -c1-3, 6-8 filename</code> list by specific range of characters <code>cut -b1-3 filename</code> list by byte size <code>cut -d: -f 6 /etc/passwd</code> list first 6th column separated by : <code>cut -d: -f 6-7 /etc/passwd</code> list first 6 and 7th column separated by : <code>ls -l | cut -c2-4</code> only print user permissions of files/dir</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#compare-files","title":"Compare files","text":"<p><code>diff</code> compares line by line <code>cmp</code> compares byte by byte</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#comtining-and-plitting-files","title":"Comtining and plitting files","text":"<p>Multiple files can be combined into one, and one file can be split into multiple files.</p> <p>In times when we have huge files, there are times when we need to either split them or compress them to send them places.</p> <p><code>split -l 2 countries sep</code> splits the file countries into files with name <code>sep</code> containing 2 lines each from original countries file</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#linux-vs-windows-commands","title":"Linux vs. Windows commands","text":"<p>Listing of a directory: <code>dir</code> vs <code>ls -l</code> Rename a file: <code>ren</code> vs <code>mv</code> Copy a file: <code>copy</code> vs <code>cp</code> Move file: <code>move</code> vs <code>mv</code> Clear screen: <code>cls</code> vs <code>clear</code> Delete file: <code>del</code> vs <code>rm</code> Compare contents of files: <code>fc</code> vs <code>diff</code> Search for a word/string in a file: <code>find</code> vs <code>grep</code> Display command help: <code>command /?</code> vs <code>man command</code> Displays your location in the file system: <code>chdir</code> vs <code>pwd</code> Displays the time: <code>time</code> vs <code>date</code></p> <p>Source: Linux for Absolute Beginners: File Comparison and Splitting by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/","title":"Help commands and pipes","text":""},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#help-commands","title":"Help commands","text":"<p>3 types of help commands:</p> <ul> <li><code>whatis command</code></li> <li>Gives shorter version of command info</li> <li><code>command --help</code></li> <li>Longer version of help for command</li> <li><code>man command</code></li> <li>Full info for command</li> </ul>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#tab-and-up-arrow","title":"Tab and up arrow","text":"<p>Tab completes available commands, files, or directories.</p> <p>Up arrow gives the last executed command.</p>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#pipes","title":"Pipes","text":"<p>Pipes are used to connect the output of one command to the input of another command.</p> <p>The symbol for a pipe is <code>|</code>. Syntax for using pipes is:</p> <pre><code>command1 [arguments] | command2 [arguments]\n</code></pre>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#adding-text-to-files","title":"Adding text to files","text":"<p>3 simple ways:</p> <ul> <li><code>vi</code> editor</li> <li>Redirect command output <code>&gt;</code> or <code>&gt;&gt;</code></li> <li><code>echo &gt;</code> or <code>&gt;&gt;</code></li> </ul> <p>Example using redirect: <code>echo \"Jerry is the main character in Seinfeld\" &gt; jerry</code> populates file <code>jerry</code> with that text.</p> <p>Doing it with <code>&gt;</code> will overwrite contents. <code>&gt;&gt;</code> will add to the existing contents.</p> <p>Can also send the output of a command to a file this way.</p> <p>Source: Linux for Absolute Beginners: Help Command and Pipes by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/","title":"Text and grep commands","text":""},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#filterstext-processors-commands","title":"Filters/text processors commands","text":"<ul> <li><code>cut</code> cut output of command</li> <li><code>awk</code> list by the columns</li> <li><code>grep</code> and <code>egrep</code> search by keywords</li> <li><code>sort</code> sorts output</li> <li><code>uniq</code> no duplicates in output</li> <li><code>wc</code> word count</li> </ul> <p>Example of <code>grep</code>: To search for directories with user read and write permissions: <code>ls -l | grep drw</code></p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#grep-usage","title":"<code>grep</code> usage","text":"<p><code>grep keyword file</code> gives only the lines of <code>file</code> that contain <code>keyword</code> <code>grep -c keyword file</code> this searches for a keyword and counts it <code>grep -i KEYword file</code> searches for keyword but ignore case <code>grep -n keyword file</code> displays the matched lines and line numbers <code>grep -v keyword file</code> get everything but the search keyword <code>grep keyword file | awk '(print $1)'</code> gives only first columns of the lines returned <code>ls -l | grep Desktop</code> only pull results that include \"Desktop\" <code>egrep -i \"keyword|keyword2\" file</code> gives all lines matching either of the keywordsx</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#wc-usage","title":"<code>wc</code> usage","text":"<p>Reads either standard input or list of files and generates: newline count, word count, byte count.</p> <p><code>wc file</code> checks file line count, word count, byte count <code>wc -l file</code> gets number of lines in a file <code>wc -w file</code> gets number of words in a file <code>wc -b file</code> gets number of bytes in a file</p> <p><code>ls -l | wc -l</code> gives the number of files/directories you have within a location (plus 1 extra line counted)</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#awk-usage","title":"<code>awk</code> usage","text":"<p>Most of the time <code>awk</code> is used to extract fields from a file or from an output.</p> <p>Source: Linux for Absolute Beginners: Text and Grep Commands by Imran Afzal, Allison.</p>"}]}