{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kieran's Notes","text":"<p>All my notes in one place.</p> <p>Disclaimer: These are my personal notes, based on various sources. If you recognize any uncited content, please notify me for proper attribution.  </p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/","title":"Compute in the cloud","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-ec2","title":"Amazon EC2","text":"<p>EC2 refers to the servers that are used to run the virtual servers.</p> <p>AWS is already running a massive amount of compute capacity, and you can use however much of that capacity you want, whenever you want.</p> <p>You just request the EC2 instances you want, and they will boot up and be ready to use in just a few minutes.</p> <p>Once you're done you can easily terminate those instances.</p> <p>You only pay for what you use. You only pay for running instances, not stopped or terminated ones.</p> <p>EC2 runs on top of physical host machines managed by AWS using virtualization. You are sharing the host with other instances (virtual machines). A hypervisor on the host machine is responsible for sharing the underlying physical resources between the virtual machines.</p> <p>This is called multi-tenancy. Hypervisor coordinates this. Hypervisor isolates VMs from each other as they share resources from the host.</p> <p>One EC2 instance is not aware of other EC2 instances even though they are on the same host.</p> <p>When you provision an EC2 instance you can choose the operating system (Windows or Linux).</p> <p>Beyond the OS you also configure what software you want running on the instance.</p> <p>You might start with a small instance, and then if it starts to max out that server you can give the instance more memory and more CPU (vertically scaling an instance). You can do this whenever you need this.</p> <p>You also control networking (types of requests, publicly or privately accessible).</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-instance-types","title":"AWS instance types","text":"<p>Gives you flexibility of choosing appropriate distribution of resources for your applications.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#general-purpose","title":"General purpose","text":"<p>Balanced. Used for variety of diverse workloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#compute-optimized","title":"Compute optimized","text":"<p>Compute intensive tasks. Gaming servers, high performance computing (HPC), etc.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#memory-optimized","title":"Memory optimized","text":"<p>Good for memory intensive tasks, like high-performance databases.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#accelerated-computing","title":"Accelerated computing","text":"<p>Floating-point number calculations, graphics processing, data pattern matching.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#storage-optimized","title":"Storage optimized","text":"<p>Workloads that require high performance for locally stored data.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#ec2-pricing","title":"EC2 pricing","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#on-demand","title":"On-demand","text":"<p>Only pay for running duration. No long-term commitments. Good for getting up and running and testing workloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#savings-plans","title":"Savings plans","text":"<p>Low pricing, commitment to specific usage terms of a year or a few.</p> <p>Reduce you instance costs when you make an hourly spend commitment to an instance family and region for a 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#reserved-instances","title":"Reserved instances","text":"<p>Workloads with predictable usage. Can pay full upfront, partial upfront, and no upfront. Standard reserve instances require you to specify instance family and size, platform description, tenancy, and region.</p> <p>Available over 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#spot-instances","title":"Spot instances","text":"<p>Get spare computing capacity, but can be reclaimed any time it is needed with a 2 minute warning. Good for batch owrkloads.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#dedicated-hosts","title":"Dedicated hosts","text":"<p>Usually for meeting certain compliance requirements, and nobody else will be using that host.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#scaling-amazon-ec2","title":"Scaling Amazon EC2","text":"<p>Scalability and elasticity refers to how capacity can grow and shrink based on business needs.</p> <p>Do not want to end up with data centers under 10% average utilization for fear of missing out on peak demand.</p> <p>Amazon EC2 auto scaling enables you to automatically add or remove Amazon EC2 instances in response to changing application demand.</p> <p>Dynamic scaling responds to changing demand.</p> <p>Predictive scaling automatically schedules the right number of Amazon EC2 instances based on predicted demand.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#auto-scaling","title":"Auto scaling","text":"<p>When creating an auto scaling group you can set the minimum number of Amazon EC2 instances that start up as soon as you create the auto scaling group (minimum capacity). You can also set the desired capacity even though your application needs a minimum of a single Amazon EC2 instance to run (desired capacity defaults to minimum capacity if not specified). Next you can set the maximum capacity so that you can scale out with demand but not past a maximum.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#elastic-load-balancing","title":"Elastic load balancing","text":"<p>Say we have an uneven distribution of traffic across our EC2 instances. We need a host to direct customers to different lines to place their order, managing the distribution of traffic.</p> <p>We apply this to AWS environments as elastic load balancing.</p> <p>Load balancer is application that takes in requests and routes them to different instances to be processed. Many off the shelf solutions that work great with AWS.</p> <p>AWS can provide this service in the form of Elastic Load Balancing. This is an AWS managed service that addresses issue of load balancing.</p> <p>Because it runs at the region level rather than on specific EC2 instances, the service is automatically highly available with no additional effort on your part.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#messaging-and-queueing","title":"Messaging and queueing","text":""},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#tightly-coupled-architecture","title":"Tightly-coupled architecture","text":"<p>If a single component has a problem it causes problems for other components or the whole system.</p> <p>Applications made up of tightly coupled components are monolithic.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#loosely-coupled-architecture","title":"Loosely coupled architecture","text":"<p>Single failure won't cause cascading failures.</p> <p>You have a queue in the middle where messages go to eventually be processed. If a given application can't process the message, it stays in the queue until it is processed by another application.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-sqs-amazon-simple-queue-service","title":"Amazon SQS (Amazon Simple Queue Service)","text":"<p>Allows you to send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available.</p> <p>Payload is the data inside the message, and it is protected until delivery.</p> <p>SQS queues are where messages are placed until they are processed.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-sns-amazon-simple-notification-service","title":"Amazon SNS (Amazon Simple Notification Service)","text":"<p>Amazon SNS can send out messages but it can also send out notifications to end users. Uses a publish subscribe model.</p> <p>Can make an Amazon SNS topic: a channel for messages to be delivered. Can then configure subscribers for that topic, and publish messages for subscribers.</p> <p>Subscribers can be web servers, email addresses, AWS Lambda functions, or several other options.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#additional-compute-services","title":"Additional compute services","text":"<p>Though EC2 is good in a lot of cases, depending on your use case you might want an alternative.</p> <p>When using EC2 you are responsible for setting up and managing your instances over time.</p> <p>AWS offers multiple serverless compute options, meaning that you don't see or access the underlying infrastructure tha`t is hosting your application. Instead, all management of the underlying environment is taken care of. All you need to do is focus on your application.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#serverless-computing","title":"Serverless computing","text":"<p>When computing with virtual servers you have to think about the servers and code, while when serverless computing you only have to think about the code.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-lambda","title":"AWS Lambda","text":"<p>AWS Lambda is a serverless compute option. More suited for quick processes, not something like deep learning.</p> <p>Allows you to run code without needing to provision or manage servers. You can run code for virtually any type of application or backend service, all with zero administration.</p> <p>Setup:</p> <ol> <li>Upload code to Lambda</li> <li>Set code to trigger from an event source</li> <li>Code only runs when triggered</li> <li>Pay only for the compute time you use</li> </ol>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-elastic-container-service-amazon-ecs","title":"Amazon Elastic Container Service (Amazon ECS)","text":"<p>Containers provide you with a standard way to package your application's code and dependencies into a single object. Can also use containers for processes and workflows in which there are essential requirements for security, reliability, and scalability.</p> <p>Using containers could delp to ensure that the application's environment remains consistent regardless of deployment.</p> <p>ECS supports Docker containers. With Amazon ECS you can use API calls to launch and stop Docker-enabled applications.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#amazon-elastic-kubernetes-service-amazon-eks","title":"Amazon Elastic Kubernetes Service (Amazon EKS)","text":"<p>Amazon EKS is a fully managed service that you can use to run Kubernetes on AWS. Kubernetes is open-source software that enables you to deploy and manage containerized applications at scale.</p>"},{"location":"aws-cloud-practitioner-essentials/compute-in-the-cloud/#aws-fargate","title":"AWS Fargate","text":"<p>Serverless compute engine for containers. Works with both Amazon ECS and Amazon EKS. When using Fargate, you do not need to provision or manage servers. Fargate manages the server infrastructure for you.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/","title":"Global infrastructure and reliability","text":"<p>High availability and fault tolerance is important. AWS operates in many regions to support this.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-global-infrastructure","title":"AWS global infrastructure","text":"<p>Events could happen that could cause lost connection to a certain data center. Most businesses end up just using backups and hoping for no disasters.</p> <p>If disaster strikes, AWS data centers will be fine. They build large data centers in central, business heavy locations.</p> <p>Each of these regions contain multiple data centers that have all the compute, storage, and services you need. Each region is connected to each other region through a high speed fiber network. You get to choose which region you want to run out of. None of your data will come into or out of that region. It is isolated.</p> <p>You might have certain government compliance requirements. E.g., any data in the Frankfurt region never leaves the Frankfurt region, unless you explicitly (with proper credentials) request an export.</p> <p>Proximity and compliance both matters. Latency is always a factor.</p> <p>Sometimes the obvious region choice may not have all of the AWS services/features available. Sometimes brand new services require new hardware and are difficult to implement everywhere.</p> <p>If budget is primary concern, you might want to operate in a different country with different pricing.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#availability-zones","title":"Availability zones","text":"<p>You don't want ot run your business out of a single building, or a single location.</p> <p>AWS has lots of data centers all around the world. Each region is made up of multiple data centers. We refer to these groups of data centers as availability zones (one or more data centers with redundant power, networking, connectivity, etc.).</p> <p>Each region consists of multiple isolated availability zones.</p> <p>As best practice it is recommended that you always run across at least two availability zones in a region, in case one gets taken out.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#edge-locations","title":"Edge locations","text":"<p>What if there is not an obvious answer to the problem of proximity for your business. You can instead cache a copy of your data locally, close to cutomers around the world. This uses concept of Content Delivery Networks (CDNs).</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#amazon-cloudfront","title":"Amazon Cloudfront","text":"<p>Service that helps deliver data, video, applications and APIs to customers around the world with low latency and high transfer speeds. Uses edge locations all around the world to accelerate communications with users no matter where they are.</p> <p>Can push content from a region to a colletion of edge locations around the world to accelerate communication and content delivery.</p> <p>AWS edge locations also run DNS called Amazon Route 53, directing customers to the correct web locations with reliably low latency.</p> <p>AWS Outposts involve basically installing a fully operational mini region right inside your own data center. If you have specific problems that can only be solved by staying within your own building, it would be right for you.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#how-to-provision-aws-resources","title":"How to provision AWS resources","text":"<p>In AWS everything is an API call.</p> <p>You can use tools like:</p> <ul> <li>AWS Management Console</li> <li>AWS Command Line Interface (CLI)</li> <li>AWS Software Development Kits (SDKs)</li> <li>Various other tools</li> </ul> <p>To create requests to send to the AWS APIs to creat and manage AWS resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-management-console","title":"AWS Management console","text":"<p>Browser based, manage visually. Useful for building test environments, AWS bills, view monitoring, and working with non-technical resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-cli","title":"AWS CLI","text":"<p>Allows you to make API calls using the terminal on your machine. Makes actions scriptable and repeatable.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-sdks","title":"AWS SDKs","text":"<p>Allow you to interact through various programming languages.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-elastic-beanstalk","title":"AWS Elastic Beanstalk","text":"<p>Allows you to provision Amazon EC2 based environments. You can just provide your application code and desired configurations to AWS Elastic Beanstalk service, which then takes that info and builds out your environment for you. Can also easily save environment configurations so that they can be deployed again.</p> <p>Gives convenience of not having to provision and manage these things separately, while still giving the visibility and control of underlying resources.</p>"},{"location":"aws-cloud-practitioner-essentials/global-infrastructure-and-reliability/#aws-cloudformation","title":"AWS Cloudformation","text":"<p>Infrastructure as code tool. Allows you to define wide variety of AWS resources with JSON or YAML text-based documents called cloud-formation templates. Allows you to define what you want to build without specifying exatly how you want to build it.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/","title":"Introduction to Amazon Web Services (AWS)","text":"<ul> <li>Amazon EC2 is a virtual server</li> <li>Client-server model: Client can be a web browser or desktop app that person interacts with, server can be services such as Amazon EC2 (a virtual server)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#deployment-models","title":"Deployment models","text":""},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#cloud-based-deployment","title":"Cloud based deployment","text":"<ul> <li>Run all parts of the application in the cloud</li> <li>Migrate existing applications to the cloud</li> <li>Design and build new applications in the cloud</li> <li>Can build applications on low-level or high-level infrastructure depending on how much management you want to do yourself</li> </ul> <p>Example: Company might create an application consisting of virtual servers, databases, and networking components that are fully based in the cloud</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#on-premises-deployment","title":"On-premises deployment","text":"<ul> <li>Deploy resources by using virtualization and resource management tools</li> <li>Increase resource utilization by using application management and virtualization technologies</li> <li>Also known as private cloud deployment</li> </ul> <p>Example: You might have applications that run on technology that is fully kept in your on-premises data center. Incorporation of application management and virtualization technologies helps to increase resource utilization</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#hybrid-deployment","title":"Hybrid deployment","text":"<ul> <li>Connect cloud-based resources to on-premises infrastructure</li> <li>Integrate cloud-based resources with legacy IT applications</li> </ul> <p>Example: You might have legacy applications that are better maintained on premises, or government regulations require your business to keep certain records on premises. Suppose a company wants to use cloud services that can automate batch data processing and analytics. However, the company has several legacy applications that are more suitable on premises and will not be migrated to the cloud. With hybrid deployment, the company would be able to keep the legacy applications on premises while benefitting from the data and analytics services that run in the cloud.</p>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#benefits-of-cloud-computing","title":"Benefits of cloud computing","text":""},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#trade-upfront-expense-for-variable-expense","title":"Trade upfront expense for variable expense","text":"<ul> <li>Upfront costs like data centers, physical servers, etc. gone</li> <li>Only pay for resources you consume</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#stop-spending-money-to-run-and-maintain-data-centers","title":"Stop spending money to run and maintain data centers","text":"<ul> <li>Eliminates requirement to spend more money and time managing infrastructure and servers</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#stop-guessing-capacity","title":"Stop guessing capacity","text":"<ul> <li>Don't have to predict how much infrastructure capacity you will need before deploying an application</li> <li>Can deploy Amazon EC2 (Elastic Compute Cloud) when needed, and pay only for the compute time you use</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#benefit-from-massive-economies-of-scale","title":"Benefit from massive economies of scale","text":"<ul> <li>Because lots of customers can aggregate in the cloud, providers, such as AWS, can achieve higher economies of scale (translates to lower prices)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#increase-speed-and-agility","title":"Increase speed and agility","text":"<ul> <li>Flexibility, easier to develop and deploy applications</li> <li>More time to experiment and innovate (access new resources within minutes)</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/intro-to-aws/#go-global-in-minutes","title":"Go global in minutes","text":"<p>Deploy applications to customers around the world quickly, while providing them with low latency.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/","title":"Migration and innovation","text":""},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-cloud-adoption-framework-caf","title":"AWS cloud adoption framework (CAF)","text":"<p>Guidance for moving over to cloud.</p> <p>Divides guidance into six perspectives:</p> <ul> <li>Business perspective<ul> <li>Create a business case for cloud adoption</li> </ul> </li> <li>People perspective<ul> <li>Evaluate organizational structures and roles, new skill and process requirements, identify gaps</li> </ul> </li> <li>Governance perspective<ul> <li>Understand how to update the staff skills and processes necessary to ensure business governance in the cloud</li> </ul> </li> <li>Platform perspective<ul> <li>Implementing new solutions on the cloud, migrating on-premises workloads to the cloud</li> </ul> </li> <li>Security perspective<ul> <li>Selection and implementation of security controls that meet the organization's needs</li> </ul> </li> <li>Operations perspective<ul> <li>Enable, run, use, operate, recover IT workloads to level agreed upon with business stakeholders</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#migration","title":"Migration","text":"<p>6 strategies for migration:</p> <ul> <li>Rehosting<ul> <li>Moving applications without changes</li> </ul> </li> <li>Replatforming<ul> <li>Making a few cloud optimizations without changing core application architecture</li> </ul> </li> <li>Refactoring/re-architecting<ul> <li>Reimagining how an application is architected and developed by using cloud-native features</li> <li>Driven by need to add features, scale, performance</li> </ul> </li> <li>Repurchasing<ul> <li>Moving from traditional license to software-as-a-service model</li> <li>Replacing an existing application with a cloud-based version</li> </ul> </li> <li>Retaining<ul> <li>Keeping applications that are critical for the business in the source environment</li> </ul> </li> <li>Retiring<ul> <li>Removing applications that are no longer needed</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snow-family","title":"AWS snow family","text":"<p>Collection of physical devices that help to physically transport up to exabytes of data into and out of AWS.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snowcone","title":"AWS Snowcone","text":"<p>Small, rugged, and secure edge computing and data transfer device. 2 CPUs, 4 GB of memory, 14 TB of usable storage.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snowball","title":"AWS Snowball","text":"<p>Snowball edge storage optimized devices well suited for large-scale data migrations and recurring transfer worklows, local computing higher capacity needs.</p> <p>Snowball edge compute optimized provides powerful computing resources for use cases like ML.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#aws-snowmobile","title":"AWS Snowmobile","text":"<p>Exabyte-scale data transfer service used to move large amounts of data to AWS.</p> <p>Up to 100 petabytes of data per Snowmobile, 45-foot long ruggedized shipping container, pulled by a semi trailer truck.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#innovation-with-aws","title":"Innovation with AWS","text":"<p>Focus on desired outcomes: current state, desired state, and problems you are trying to solve.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#serverless-applications","title":"Serverless applications","text":"<p>Don't require you to provision, maintain, or administer servers. AWS Lambda is example.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#artificial-intelligence","title":"Artificial intelligence","text":"<p>For example:</p> <ul> <li>Convert speech to text with Amazon Transcribe</li> <li>Discover patterns in text with Amazon Comprehend</li> <li>Identify potentially fraudulent online activities with Amazon Fraud Detector</li> <li>Build voice and text chatbots with Amazon Lex</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#machine-learning","title":"Machine learning","text":"<p>Amazon SageMaker to remove difficult work from process and empower you to build, train, and deploy ML models quickly.</p>"},{"location":"aws-cloud-practitioner-essentials/migration-and-innovation/#amazon-q-developer","title":"Amazon Q Developer","text":"<p>ML code generator. Analyzes, generates comments. Automatically generates suggestions. Can be used as IDE extension.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/","title":"Monitoring and analytics","text":""},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/#aws-cloudwatch","title":"AWS CloudWatch","text":"<p>Monitor and manage various metrics, configure alarms based on those metrics. Can send notifications when alarms are triggered.</p> <p>Has a dashboard feature where you can see all your metrics. Dashboards can also be customized.</p>"},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/#aws-cloudtrail","title":"AWS CloudTrail","text":"<p>Records all API calls for your account, meaning that you always have a record of anything that has happened.</p> <p>Also has \"insights\" feature allowing it to automatically detect unusual API activities in your account.</p>"},{"location":"aws-cloud-practitioner-essentials/monitoring-and-analytics/#aws-trusted-advisor","title":"AWS Trusted Advisor","text":"<p>Checks everything about your AWS setup and gives you recommendations for changes, etc.</p> <p>Green check means no problems, orange triangle means you should investigate, and red circle means you should make a change.</p> <p>Considers: cost optimization, performance, security, fault tolerance, service limits. </p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/","title":"Networking","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-virtual-private-cloud-vpcs","title":"Amazon Virtual Private Cloud (VPCs)","text":"<p>A VPC lets you provision a logically isolated section of the AWS cloud where you can launch AWS resources in a virtual network that you define.</p> <p>The private and public grouping of resources are known as subnets, and they are ranges of IP addresses in your VPCs.</p> <p>Essentially your own private network in AWS. Allows you to define your private IP range for your AWS resources, and you place things like EC2 instances and ELBs (Elastic Load Balancers) inside of your VPC.</p> <p>For some VPCs you might have internet-facing resources that the public should be able to reach, like a public website. In other scenarios you might have resources that you only want to be reachable if someone is logged into your private network, such as an HR application or backend database.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#internet-gateway-igw","title":"internet gateway (IGW)","text":"<p>In order to allow traffic from the public internet to flow into and out of your VPC, you must attach what is called an internet gateway, or IGW, to your VPC. This is like a doorway that is open to the public.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#virtual-private-gateway","title":"Virtual private gateway","text":"<p>If we don't want just anyone to be able to access these resources, we want a private gateway that only lets in people coming from an approved network.</p> <p>This is called a virtual private gateway, and allows you to create a VPN connection between a private network (like your on-premises data center) and your VPC.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#direct-connect","title":"Direct connect","text":"<p>The problem with using a VPN connection is they use bandwidth being shared by many people using the internet. To get around this you can use AWS direct connect, which allows you to establish a completely private, dedicated fiber connection from your data center to AWS. This can help with high regulatory and compliance needs, as well as any bandwidth issues.</p> <p>One VPC might have multiple types of gateways attached for multiple types of resources all residing in the same VPC, just in different subnets.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#subnets-and-network-access-control-lists","title":"Subnets and network access control lists","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#subnets","title":"Subnets","text":"<p>Public subnets contain resources that need to be accessible by the public, such as an online store's website.</p> <p>Private subnets contain resources that should be accessible only through your private network, such as a database that contains customers' personal information and order histories.</p> <p>Internet gateways only cover the perimeter. We need to cover other layers of security as well.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#network-hardening","title":"Network hardening","text":"<p>The only technical reason to use subnets in a VPC is to control access to gateways. Subnets can also control packet permissons. Every packet that tried to cross over the subnet boundary gets checked against the network access control list (network ACL). This is to see if the packet has permissions to leave or enter the subnet. Network ACL kinda acts like a border control officer.</p> <p>By default, your AWS account's network access control list is stateless and allows all inbound and outbound traffic.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#security-groups","title":"Security groups","text":"<p>This does not solve the problem of different levels of security for different EC2 instances within the subnet though. You need instance-level security as well. For this we can use security groups. You can modify these groups to accept specific types of traffic. These are like a doorman at a building or hotel. You may been let into the country by the border control officer, but the doorman of the building might turn you away.</p> <p>By default, security groups allow any traffic out and deny all incoming traffic. Key difference between network ACL and security group is a security group is stateful, meaning that it remembers what to let in or out. A network ACL checks every packet regardless.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#global-networking","title":"Global networking","text":""},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-route-53","title":"Amazon Route 53","text":"<p>Highly available and scalable DNS. Think of it as a translation service, but instead of translating languages, it translates website names into IP addresses.</p> <p>Some of the route 53 routing policies:</p> <ul> <li>Latency based</li> <li>Geolocation DNS<ul> <li>Direct traffic based on where customer is located</li> </ul> </li> <li>Geoproximity</li> <li>Weighted round robin</li> </ul> <p>You can also use route 53 to buy and manage domain names.</p>"},{"location":"aws-cloud-practitioner-essentials/networking/#amazon-cloudfront","title":"Amazon Cloudfront","text":"<p>Using edge locations with cached content to better serve content around the world using CDNs. A CDN is a network that delivers edge content to users based on their geographic location.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/","title":"Pricing and support","text":""},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-free-tier","title":"AWS Free Tier","text":"<p>Has always free, 12 months free, and trial options.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-pricing-concepts","title":"AWS Pricing Concepts","text":"<p>Pay for what you use. Pay less when you reserve. Pay less when you use more.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-pricing-calculator","title":"AWS Pricing Calculator","text":"<p>Get estimates for different AWS services. Can organize them by groups (a group could represent one of your cost centers, for example).</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-lambda-pricing","title":"AWS Lambda Pricing","text":"<p>Charged based on number of requests for your functions and time it takes them to run. 1 mill free requests, 3.2 million seconds of compute time per month.</p> <p>Compute Savings Plan: lower costs, commit to consistent usage over 1-year or 3-year term.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#amazon-ec2-pricing","title":"Amazon EC2 Pricing","text":"<p>Pay only for compute time you use.</p> <p>Can significantly reduce costs using Spot instances.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#amazon-s3-pricing","title":"Amazon S3 Pricing","text":"<p>Cost components:</p> <ul> <li>Storage</li> <li>Requests and data retrievals</li> <li>Data transfer</li> <li>Management and replication</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-billing-dashboard","title":"AWS billing dashboard","text":"<ul> <li>Compare current balance with previous month, get forecast based on usage</li> <li>View spending by service</li> <li>View free tier usage by service</li> <li>Cost explorer, create budgets</li> <li>Purchase and manage savings plans</li> <li>AWS cost and usage reports</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#consolidated-billing","title":"Consolidated billing","text":"<p>Receive single bill for all accounts in your organization (up to 4 by default).</p> <p>Can review itemized charges on each account.</p> <p>Can share bulk idscount pricing.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-budgets","title":"AWS budgets","text":"<p>Create budgets to plan service usage, costs, instance reservations.</p> <p>Info updates three times a day to help determine whether meeting budget.</p> <p>Get notified when usage exceeds.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-cost-explorer","title":"AWS cost explorer","text":"<p>Visualize, understand, manage AWS costs and usage.</p> <p>Custom filters and groups.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-support","title":"AWS support","text":"<p>Support plans:</p> <ul> <li>Basic</li> <li>Developer</li> <li>Business</li> <li>Enterprise on-ramp</li> <li>Enterprise</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#basic-support","title":"Basic support","text":"<p>Free for all customers. Whitepapers, documentation, support communities. Can contact AWS for billing questions and service limit increases.</p> <p>Limited selection of AWS trusted advisor checks.</p> <p>AWS personal health dashboard: provides alerts and guidance when AWS is experiencing events affecting you.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#developer-business-enterprise-on-ramp-enterprise-support","title":"Developer, business, enterprise on-ramp, enterprise support","text":"<p>Additional ability to open unrestricted number of technical support cases. Pay-by-month, no long-term contracts.</p> <p>From lowest to highest cost: Developer, business and enterprise on-ramp, enterprise.</p> <p>Only business, enterprise on-ramp, and enterprise support include all trusted advisor checks.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#technical-account-manager-tam","title":"Technical account manager (TAM)","text":"<p>Only available to enterprise on-ramp and enterprise support plans.</p> <p>Primary point of contact.</p> <p>Helps across all AWS services.</p> <p>Expert engineering guidance.</p>"},{"location":"aws-cloud-practitioner-essentials/pricing-and-support/#aws-marketplace","title":"AWS marketplace","text":"<p>Digital catalog including thousands of software listings from independent software vendors. Find, test, and buy software that runs on AWS.</p> <p>Explore by industry and use case.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/security/","title":"Security","text":""},{"location":"aws-cloud-practitioner-essentials/security/#shared-responsibility-model","title":"Shared responsibility model","text":"<p>AWS controls security of the cloud, while customers control security in the cloud.</p> <p>Consider a homeowner and a homebuilder. The builder (AWS) is responsible for constructing your house and ensuring that it is solidly built. As the homeowner (the customer), it is your responsibility to secure everything in the house by ensuring that the doors are closed and locked.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#user-permissions-and-access","title":"User permissions and access","text":"<p>AWS root user: Access and control any part of the account. You do not want to use the root user for everything of course.</p> <p>You can control access in a granular way using AWS Identity and Access Management (AWS IAM). You can use this to create IAM users that by default do not have any permissions.</p> <p>You have to explicitly give IAM users permissions to do anything in that account. Following the principle of least privilige, you only give users access to what they need.</p> <p>An IAM policy is a JSON document describing what API calls a user can or cannot make.</p> <p>One way to make it easier to manage your users and their permissions is to organize them into IAM groups. Groups are groupings of user policies.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#roles","title":"Roles","text":"<p>Roles have associated permissions that can allow or deny certain actions, and can be assumed for temporary amounts of time.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-organizations","title":"AWS Organizations","text":"<p>AWS Organizations is a central location to manage multiple AWS accounts. Also has consolidated billing. Can also implement hierarchical groupings of accounts. Also have control over the AWS service and API actions access control.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#service-control-policies-scps","title":"Service control policies (SCPs)","text":"<p>Enable you to place restrictions on the AWS services, resources, and individual API actions that users and roles in each account can access.</p> <p>SCPs can be applied to organizational units and individual member accounts.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#compliance","title":"Compliance","text":"<p>AWS complies with a long list of assurance programs.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-artifact","title":"AWS Artifact","text":"<p>Gain access to compliance reports completed by third parties.</p> <p>Suppose your company needs to sign an agreeement with AWS regarding your use of certain types of information throughout AWS services. You can do this through AWS Artifact Agreements.</p> <p>Next, suppose a member of your company's development team is building an application and needs more information about their responsibility for complying with certain regulatory standards. You can advice them to access this information in AWS Artifact Reports.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#denial-of-service-attacks","title":"Denial-of-service attacks","text":"<p>Objective of DDoS attack is to shut down system by overwhelming it. Leverages other machines to unknowingly attacking your infrastructure. Key to a powerful attack if if the attacker creates the most work possible for the infrastructure while putting in the least amount of effort possible.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#udp-flood","title":"UDP flood","text":"<p>Example is asking the weather service to send a bunch of information to a return address (the return address of the service you are trying to cripple) to overload it without it asking for that info.</p> <p>Solution: Security groups that only allow in proper request traffic that we want.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#http-level-attacks","title":"HTTP level attacks","text":"<p>Look like normal customers asking for normal things, but repeated over and over by bot machines.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#slowloris-attack","title":"Slowloris Attack","text":"<p>Attacker pretends to have a terribly slow connection, meanwhile until their request finishes you can't move on to the next one.</p> <p>Solution: Elastic load balancer. To overwhelm ELB you would have to overwhlem the entire AWS region.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-shield-with-aws-waf","title":"AWS Shield with AWS WAF","text":"<p>WAF uses a web application firewall to filter incoming traffic.</p> <p>AWS Shield Standard automatically protects all AWS customers at no cost. It protects your AWS resources from the most common, frequently ocurring types of DDoS attacks.</p> <p>AWS Shield Advanced is a paid service that provides detailed attack diagnostics and the ability to detect and mitigate sophisticated DDoS attacks.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#additional-security-services","title":"Additional security services","text":""},{"location":"aws-cloud-practitioner-essentials/security/#aws-key-management-service-aws-kms","title":"AWS key management service (AWS KMS)","text":"<p>Enables you to perform envryption operations through the use of cryptographic keys. A cryptographic key is a random string of digits used for locking (encrypting) and unlocking (decrypting) data. Can use AWS KMS to create, manage, and use cryptographic keys.</p> <p>Can choose specific levels of access control you need for your keys.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#aws-waf","title":"AWS WAF","text":"<p>Web application firewall that lets you monitor network requests that come into your web applications.</p> <p>Works together with CloudfFront and Application Load Balancer.</p> <p>Uses a web access control list (ACL) to protect your AWS resources.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#amazon-inspector","title":"Amazon inspector","text":"<p>Can perform automated security assessments, and returns a list of security findings.</p>"},{"location":"aws-cloud-practitioner-essentials/security/#amazon-guardduty","title":"Amazon GUardDuty","text":"<p>Provides intelligent threat detection for your AWS infrastructure and resources. Identifies threats by continuously monitoring the network activity and account behavior within your AWS environment.</p> <p>GuardDuty findings can be reviewed in the AWS management console.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/","title":"Storage and databases","text":"<p>As EC2 instances run applications, those applications will often require block-level storage. In block level storage, when something is changed only that aspect is rewritten rather than the entire thing. This makes it an efficient storage type when working with databases, enterprise software or file systems.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#instance-stores-and-amazon-elastic-block-store-amazon-ebs","title":"Instance stores and amazon elastic block store (Amazon EBS)","text":""},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#instance-store-volumes","title":"Instance store volumes","text":"<p>When you launch an EC2 instance it might provide you with local storage called instance store volumes. These are physically attached to the host your EC2 instance is running on top of. You can write to it just like a normal hard drive. The problem here is that if you terminate the instance or host, all data in the instance store volumes will be deleted. This is because you often start up an instance on a different host.</p> <p>So these are useful in situations where you can afford to lose the data being written to the drives.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-elastic-block-store-amazon-ebs","title":"Amazon elastic block store (Amazon EBS)","text":"<p>If you do not want to be losing your database every time your instance is terminated, you can use Amazon EBS. This allows you to create virtual hard drives that are not attached to the host the EC2 instance is running on. The data persists through stops and starts of an instance.</p> <p>EBS allows you to create incremental backups of your database called snapshots.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-simple-storage-service","title":"Amazon simple storage service","text":"<p>Store and retrieve an unlimited amount of data. Store data as objects, in buckets.</p> <p>in object storage, each object consists of data, metadata, and a key.</p> <p>Maximum object size of 5 TB. Can version objects, and create multiple buckets.</p> <p>Another way to use S3 is static website hosting (a bunch of static HTML files).</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-s3-standard-infrequent-access-s3-standard-ia","title":"Amazon S3 standard-infrequent access (S3 Standard-IA)","text":"<p>Used for data accessed less frequently, requires rapid access when needed. Good place to store backups, disaster recovery files, etc.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-s3-glacier-flexible-retrieval","title":"Amazon S3 Glacier Flexible Retrieval","text":"<p>Good for retaining data for several years for auditing purposes. Can either move data to it or use vaults populated with archives. Can use a S3 Glacier Vault lock policy to meet compliance requirements (can use policies like write once/read many WORM).</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-s3-glacier-deep-archive","title":"Amazon S3 Glacier Deep Archive","text":"<p>Good for archival data.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#lifecycle-policies","title":"Lifecycle policies","text":"<p>Policies that automatically move data between tiers. For example, keeping an object in S3 standard for 90 days then moving it to S3 standard IA for 30 days, and so on...</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#comparing-amazon-ebs-and-amazon-s3","title":"Comparing Amazon EBS and Amazon S3","text":""},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-ebs","title":"Amazon EBS","text":"<ul> <li>Sizes up to 16 TiB</li> <li>Survive termination of their EC2 instance</li> <li>Solid state by default</li> <li>HDD options</li> </ul> <p>An EBS volume must be located in the same Availability Zone as the Amazon EC2 instance to which it is attached.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-simple-storage-service-s3","title":"Amazon Simple Storage Service (S3)","text":"<ul> <li>Unlimited storage</li> <li>Individual objects up to 5 TBs</li> <li>Write once/read many</li> <li>99.999999999% durability</li> </ul> <p>Difference between object storage and block storage: Object storage treats any file as a complete, discrete object. Great for documents, images, and video files that get uploaded and consumed as entire objects. However, any time a change happens you must re-upload the entire file. Block storage breaks those files down into component parts, meaning that when you make an edit to one part, the edit only updates the blocks where those bits live.</p> <p>If you are using only complete objects, S3 is victorious. If you are doing complex read/write change functions, then EBS is better.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-elastic-file-system-amazon-efs","title":"Amazon Elastic File System (Amazon EFS)","text":"<p>Managed file system. Common for businesses to have shared file systems across their applications. Might have multiple servers running analytics on data stored in a shared file system. With EFS you can leave the file system in place and let AWS handle all the scaling and replication.</p> <p>EFS allows you to have multiple instances that can access the data in EFS at the same time. Scales up and down as needed.</p> <p>Data in an Amazon EFS file system can be accessed concurrently from all the Availability Zones in the Region where the file system is located.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#what-is-the-difference-between-ebs-and-efs","title":"What is the difference between EBS and EFS?","text":"<p>EBS volumes attach to EC2 instances and are an availability zone level resource. In order to attach EC2 to EBS you need to be in the same AZ. Volumes also do not automatically scale to give you more storage.</p> <p>EFS can have multiple instances reading and writing simultaneously. It is a true Linux file system, and a regional resource. So any EC2 instance in the region can write to the EFS. Also automatically scales.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-relational-database-services","title":"Amazon relational database services","text":"<p>If you want to keep track of relationships between different data, you should use a relational database management system (RDBMS).</p> <p>AWS supports multiple databases like MySQL, PostgreSQL, Oracle, and Microsoft SQL Server.</p> <p>To migrate your databases to AWS you can perform a lift and shift to an EC2 instance.</p> <p>You can also use a more managed service like Amazon Relational Database Service (Amazon RDS). Comes with automated patching, backups, redundancy, failover, disaster recovery, etc.</p> <p>Amazon Aurora is another option that is even more managed. Comes in MySQL and PostgreSQL, and comes in at 1/10th the cost of commercial databases. Data is replicated across facilities, and you can upload up to 15 read replicas. There are also continuous backups to S3, so you always have a backup ready to restore.</p> <p>Amazon Aurora is considered to be part of Amazon RDS.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-dynamodb","title":"Amazon DynamoDB","text":"<p>At its most basic level it is a serverless database. You don't need to manage the underlying instances or infrastructure powering it. You can create tables populated with items that have attributes. The burden of operating an available database is much lower when using DynamoDB.</p> <p>Does not use SQL. Rigid SQL databases can have performance and scaling issues when under stress. Might not be best for dataset that is not rigid and might be accessed at a very high rate.</p> <p>DynamoDB is a non-relational database. You can add and remove attributes from items in a table anytime, and not every item in a table has to have the same attributes. You write queries based on a small subset of attributes designated as keys. Queries of this type generally focus on a collection of items from one table rather than across multiple tables. Allows it to be quick and scalable.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#comparing-amazon-rds-and-amazon-dynamodb","title":"Comparing Amazon RDS and Amazon DynamoDB","text":""},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-rds","title":"Amazon RDS","text":"<ul> <li>Automatic high availability; recovery provided</li> <li>Customer ownership of data</li> <li>Customer ownership of schema</li> <li>Customer control of network</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-dynamodb_1","title":"Amazon DynamoDB","text":"<ul> <li>Key-value</li> <li>NoSQL</li> <li>Massive throughput capabilities</li> <li>PB size potential</li> <li>Granular API access</li> </ul>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#which-one-is-right-for-you","title":"Which one is right for you?","text":"<p>If you need complex relational joins between tables, you need RDS. For pretty much anything else, you could use DynamoDB. If you basically just need lookup tables (single table stuff), DynamoDB would be great.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-redshift","title":"Amazon Redshift","text":"<p>Once data becomes too complex to handle with traditional relational databases, you've entered the world of data warehouses. Good for historical analytics. As long as your data question involves looking backward, then a data warehouse could be right for that situation.</p> <p>Amazon Redshift is data warehousing as a service, and is massively scalable. Can achieve much better performance compared to other database technologies for these kinds of queries. When you need big data business intelligence solutions, Redshift is a good choice.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#aws-data-migration-service","title":"AWS Data Migration Service","text":"<p>Does AWS have a magical way to help you migrate your existing database?</p> <p>Essentially migrate data between a source database and target database, with the source database remaining fully operational during the migration. The source and target databases don't even have to be the same type.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#homogeneous-databases","title":"Homogeneous databases","text":"<p>Migration between two databases of same type. The source database could be on premises running on EC2 instances, or can be an Amazon RDS database. The target database can be Amazon EC2, or Amazon RDS.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#heterogeneous-migration","title":"Heterogeneous migration","text":"<p>When the source and target are of different types. 2-step process, uses conversion tool to match the schema and database code, then you migrate it.</p> <p>Other use cases:</p> <ul> <li>Development and test database migrations<ul> <li>When you want your developers to test against production data but without affecting production users, so you create a copy</li> </ul> </li> <li>Database consolidation<ul> <li>When you have several databases and want to combine them into one</li> </ul> </li> <li>Continuous replication<ul> <li>When you use DMS to perform continuous database replication (disaster recovery, or geographic separation)</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#additional-database-services","title":"Additional database services","text":"<p>What if you need a full content management system?</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-documentdb-mongodb-compatability","title":"Amazon DocumentDB (MongoDB compatability)","text":"<p>Content management, catalogs, user profiles, etc.</p> <p>What if you had a social network and wanted to see who is connected to who etc.?</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-neptune","title":"Amazon Neptune","text":"<p>Graph database engineered for social networking. Also great for fraud detection needs. Or tracking a supply chain, or banking records requiring 100% immutability.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-managed-blockchain","title":"Amazon Managed Blockchain","text":"<p>Blockchain solution.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-quantum-ledger-database","title":"Amazon Quantum Ledger Database","text":"<p>immutable records where any entry can never be removed from the audits.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#database-accelerators","title":"Database accelerators","text":"<p>Caching layers that can hlp improve the read times of common requests.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-elasticache","title":"Amazon ElastiCache","text":"<p>Caching layers without heavy lifting.</p>"},{"location":"aws-cloud-practitioner-essentials/storage-and-databases/#amazon-dynamodb-accelerator","title":"Amazon DynamoDB Accelerator","text":"<p>An in-memory cache for DynamoDB.</p> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"aws-cloud-practitioner-essentials/well-architected-framework/","title":"Well-architected framework","text":"<p>Helps you understand how to best design and operate your AWS cloud system.</p> <p>Based on six pillars:</p> <ul> <li>Operational excellence<ul> <li>Ability to run and monitor systems to deliver business value and to continually improve supporting processes and procedures</li> </ul> </li> <li>Security<ul> <li>Ability to protect information, systems, and assets while delivering business value through risk assessments and mitigation strategies</li> </ul> </li> <li>Reliability<ul> <li>Ability of a system to recover from disruptions, dynamically acquire resources, mitigate disruptions, etc.</li> </ul> </li> <li>Performance efficiency<ul> <li>Ability to use computing resources efficiently to meet system requirements and to maintain that efficiency</li> </ul> </li> <li>Cost optimization<ul> <li>Ability to run systems to deliver business value at lowest price point</li> </ul> </li> <li>Sustainability<ul> <li>Ability to continually improve sustainability impacts by reducing energy consumption and increasing efficiency across all components of a workload by maximizing the benefits from the provisioned resources and minimizing the total resources required</li> </ul> </li> </ul>"},{"location":"aws-cloud-practitioner-essentials/well-architected-framework/#benefits-of-aws-cloud","title":"Benefits of AWS cloud","text":"<p>Advantages of cloud computing:</p> <ul> <li>Trade upfront expense for variable expense</li> <li>Benefit from massive economies of scale</li> <li>Stop guessing capacity</li> <li>Increase speed and agility</li> <li>Stop spending money running and maintaining data centers</li> <li>Go global in minutes</li> </ul> <p>Source: AWS Cloud Practitioner Essentials, AWS Training &amp; Certification.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/","title":"Where in the genome does DNA replication begin?","text":"<p>Replication begind in a genomic region called the replication origin (denoted \\(oriC\\)).</p> <p>In the context of gene therapy it is important to figure out where the \\(oriC\\) is within the genome so that it can be preserved. This is because it is necessary for gene replication, which is an important part of gene therapy.</p> <p>Research has shown that the region of the bacterial genome encoding \\(oriC\\) is typically a few hundred nucleotides long.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#finding-the-oric","title":"Finding the \\(oriC\\)","text":"<p>One way we can try to find the \\(oriC\\) is by looking for the \\(DnaA\\) box, a DNA sequence that is essentially a message telling the \\(DnaA\\) protein: \"bind here!\"</p> <p>We want to look for something that stands out in \\(oriC\\), in other words, some sort of pattern.</p> <p>One way we can define this problem is as a pattern counting problem, where we search for the most frequent \\(k\\)-mers, or, strings of length \\(k\\).</p> <p>We can use the following algorithm:</p> <pre><code>def pattern_count(text, pattern):\n    count = 0\n    for i in range(0, len(text)-len(pattern)):\n        if text[i:(i+len(pattern))] == pattern:\n            count += 1\n    return count\n</code></pre>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#the-frequent-words-problem","title":"The Frequent Words problem","text":"<p>Let us extend this further. We can generalize to wanting to find the most frequent \\(k\\)-mer for all values of \\(k\\) possible for the text.</p> <p>We say that \\(Pattern\\) is a most frequent \\(k\\)-mer in \\(Text\\) if it mazimizes <code>pattern_count(text, pattern)</code> among all \\(k\\)-mers.</p> <p>So our problem is as follows:</p> <p>Input: A string \\(Text\\) and an integer \\(k\\)</p> <p>Output: All most frequent \\(k\\)-mers in \\(Text\\)</p> <p>There will be \\(|Text|-k+1\\) \\(k\\)-mers to check in a given string \\(Text\\).</p> <p>To implement this algorithm <code>frequent_words</code> we need to store an array <code>count</code> containing the number of occurrences of each pattern \\(Pattern = Text(i,k)\\), where <code>count[i]</code> stores <code>count(text, pattern)</code> for \\(Pattern = Text(i,k)\\). So if we have a pattern of length 3, <code>count[2]</code> would be the number of occurrences of the substring from index 2 to index (2 + 3) - 1 = 4.</p> <p>Here is the algorithm:</p> <pre><code>def frequent_words(text, k):\n    count = []\n    frequent_patterns = []\n    max_count = 0\n    for i in range(0, len(text)-k):\n        pattern = text[i:(i+k)]\n        count.append(pattern_count(text, pattern))\n        if count[i] &gt; max_count:\n            max_count = count[i]\n    for i in range(0, len(text)-k):\n        if count[i] == max_count:\n            frequent_patterns.append(text[i:(i+k)])\n    frequent_patterns = list(dict.fromkeys(frequent_patterns))\n    return frequent_patterns\n</code></pre> <p>This works, but it is not very efficient.</p> <p>Each \\(k\\)-mer requires \\(|Text| - k + 1\\) checks, each requiring as many as \\(k\\) comparisons, so overall # of steps of <code>pattern_count(text, pattern)</code> is \\((|Text| - k + 1) \\cdot k\\).</p> <p>Additionally, <code>frequent_words</code> must call <code>pattern_count</code> \\(|Text| - k + 1\\) times (once for each \\(k\\)-mer of \\(Text\\)), so its overall number of steps is \\((|Text| - k + 1) \\cdot (|Text| - k + 1) \\cdot k\\).</p> <p>To simplify, its complexity is \\(\\mathcal{O}(|Text|^2\\cdot k)\\).</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#another-way-of-doing-this","title":"Another way of doing this","text":"<p>With the goal of making our algorithm more efficient, we can address the main issue: we look through the entire string for every different \\(k\\)-mer pattern. Our new idea is to pass through the string once for each \\(k\\), maintaining a count of each possible \\(k\\)-mer and adding to each \\(k\\)-mer's count whenever we pass over it. Since these strings are made up of four different possible characters, we will have \\(4^k\\) possible \\(k\\)-mers for each value of \\(k\\).</p> <p>We define the frequency array of a string \\(Text\\) as an array of length \\(4^k\\), where the \\(i\\)-th element of the array holds the number of times that the \\(i\\)-th \\(k\\)-mer (in the lexographic order) appears in \\(Text\\).</p> <p>To make this work we need to be able to transform strings to integers and back to strings. We can figure out the possible \\(k\\)-mers, order them lexographically, then number them based on that ordering. Based on that numbering we can encode our string as an integer, where each \\(k\\)-mer is described by its number in the lexographic ordering.</p> <p>The following algorithms are for encoding and decoding out representations:</p> <p>Encoding:</p> <pre><code>def pattern_to_number(pattern):\n    if not pattern:\n        return 0\n    symbol_to_number = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n    result = 0\n    for char in pattern:\n        result = result * 4 + symbol_to_number[char]\n    return result\n</code></pre> <p>Decoding:</p> <pre><code>def number_to_pattern(index, k):\n    if k == 0:\n        return \"\"\n    number_to_symbol = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n    prefix_index = index // 4\n    remainder = index % 4\n    symbol = number_to_symbol[remainder]\n    if k == 1:\n        return symbol\n    else:\n        prefix_pattern = number_to_pattern(prefix_index, k-1)\n        return prefix_pattern + symbol\n</code></pre> <p>We can now move on to the problem of generating frequency arrays. We can first initialize every \\(4^k\\) elements in the frequency array to zero, then make a single pass down the string. For each \\(k\\)-mer we encounter, we add 1 to the value of the frequency array corresponding to it.</p> <p>If working in Python we can use a dict for our frequency array:</p> <pre><code>def frequency_array(k):\n    frequencies = {}\n    for i in range(0, (4**k)):\n        frequencies[number_to_pattern(i, k)] = 0\n    return frequencies\n</code></pre> <p>This uses our previously built <code>number_to_pattern</code> function to populate our dictionary with keys corresponding to each possible \\(k\\)-mer, in lexicographical order.</p> <p>We can now put it all together with a complete algorithm that is faster than our original solution:</p> <pre><code>def faster_frequent_words(text, k):\n    frequencies = frequency_array(k)\n    for i in range(len(text) - k + 1):\n        frequencies[text[i:i+k]] += 1\n    max_value = max(frequencies.values())\n    print(frequencies)\n    return [key for key, value in frequencies.items() if value == max_value]\n</code></pre> <p>This algorithm initializes a dict of all possible \\(k\\)-mers. It then iterates through \\(Text\\) and adds each \\(k\\)-mer occurrence to the frequency dict. We then get the maximum value of the frequency dict, and iterate through the frequency dict to check for strings that match that maximum value. Strings that have occurrences equal to the max are returned.</p>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#how-do-you-compute-number-to-pattern","title":"How do you compute number to pattern?","text":"<p>They use a recursive algorithm.</p> <p>We observe that if we remove the final symbol from all lexicographically ordered \\(k\\)-mers, the resulting list is still ordered lexicographically.</p> <p>We also see that once we do this, every (\\(k\\)-1)-mer in the resulting list is repeated four times.</p> <p>So, in the case of \\(3\\)-mers and the pattern of \\(AGT\\) we see that</p> <p>\\(PatternToNumber(AGT) = 4 \\cdot PatternToNumber(AG) + SymbolToNumber(T) \\\\  = 8 + 3 = 1\\)</p> <p>Where \\(SymbolToNumber(symbol)\\) is the function transforming symbols \\(A, C, G, T\\) into their respective integers 0, 1, 2, and 3.</p> <p>By removing the final symbol of \\(Pattern\\), denotes \\(LastSymbol(Pattern)\\), we obtain a \\((k-1)\\)-mer that we denote as \\(Prefix(Pattern)\\).</p> <p>We can generalize this observation to the following formula:</p> <p>$ PatternToNumber(Pattern) = 4 \\cdot PatternToNumber(Prefix(Pattern)) + SymbolToNumber(LastSymbol(Pattern)) $</p> <p>So we can construct the following recursive algorithm:</p> <pre><code>def pattern_to_number(pattern):\n    if not pattern:\n        return 0\n    symbol = pattern[-1]\n    prefix = pattern[:-1]\n    return 4 * pattern_to_number(prefix) + symbol_to_number(symbol)\n</code></pre>"},{"location":"bioinformatics-algorithms/where-in-genome-does-dna-replication-begin/#references","title":"References","text":"<p>Compeau, P., &amp; Pevzner, P. (2015). Bioinformatics algorithms: An active learning approach (Vol. 1). Active Learning Publishers.</p>"},{"location":"fundamental-chess-openings/d4-openings/","title":"d4 openings","text":"<p>More strategically oriented than e4.</p> <p>Generally 1 e4 is about taking initiative, while 1 e5 is about balancing the center.</p>"},{"location":"fundamental-chess-openings/d4-openings/#why-is-e4-more-direct","title":"Why is e4 more direct?","text":"<p>This is because the course of action, most of the time, following e4 is much more obvious. Often what will happen is 1 e4 e5. e5 is the book move for black because it fights for the centre by controlling d4 and taking space.</p> <p>The obvious response for white is 2 Nf3, or 2 f4. Either way white's object of attack is unambiguous.</p>"},{"location":"fundamental-chess-openings/d4-openings/#the-more-strategic-d4","title":"The more strategic d4","text":""},{"location":"fundamental-chess-openings/d4-openings/#1-d4-d5-closed-game","title":"1 d4 d5 (Closed Game)","text":"<p>One of the two logical responses is 1 d4 d5, with the main difference of this versus e4 being that the d5 pawn is defended (unlike the e5 pawn in 1 e4 e5).</p> <p>1 d4 d5 can actually lead to white being able to attac black's stronghold because of the possibility of 2 c4 (Queen's Gambit).</p> <p>If black declines by protecting the panw on d5 with 2 ... e6 (Queen's Gambit Declines) or 2 ... c6 (Slav Defence), white gains space and can break with e4 later. This can be facilitated by white playing Nc3 and then e4 at some point.</p> <p>If black accepts by taking the white pawn on c4 with 2 dxc4 (Queen's Gambit Accepted), white can regain the lost material with better development by playing e4 or e3 and controlling the center.</p>"},{"location":"fundamental-chess-openings/d4-openings/#1-d4-nf6-indian-defense","title":"1 d4 Nf6 (Indian Defense)","text":"<p>Has the benefit of controlling e4 and prevents advance of d4 pawn.</p>"},{"location":"fundamental-chess-openings/d4-openings/#2-c4-e6","title":"2 c4 e6","text":"<p>The less-thought-out line of this move would be for white to continue on with the idea of 2 c4, and for black to play 2 ... e6 in the hopes of 3 ... d5 to fight for the center. This move also opens up a diagonal for blacks bishop.</p> <p>There are actually other good ways for black to proceed after 2 c4. One way is with 2 ... e6 3 Nc3 Bb4 (Nimzo-Indian Defence).</p> <p>Here, instead of trying to fight for the center black opts for rapid development of their bishop. It pins the knight on c3 which had been protecting the e4 square in anticipation of white moving its pawn there. That means that white can no longer easily dominate the center.</p> <p>The idea here is to give up on fighting for the center early on with pawn and instead stop white from taking any more control while developing your pieces.</p> <p>Black can now castle kingside as well.</p> <p>White can play a3 here to attack the bishop, but in this situation black can play 4 ... Bxc3+, forcing white to take with the b2 pawn and double up pawns on the c file.</p> <p>If instead of playing 3 Nc3 white plays 3 Nf3, black has two alternatives. They can play 3 ... b6 (Queen's Indian Defence), or 3 ... Bb4+ (Borgoljubow Defence).</p> <p>The idea of 3 ... b6 is to get the black bishop on b7 so that it controls the e4 and d5 squares. One piece of modern theory is piece pressure is better than pawn occupation.</p> <p>The idea of 3 ... Bb4+ is that white must block the bishop and this can either transpose into a Nimzo-Indian Defence or result in an exchange of pieces.</p>"},{"location":"linux-essentials/linux-administration/utility-commands-user-management/","title":"Utility commands and user management","text":""},{"location":"linux-essentials/linux-administration/utility-commands-user-management/#linux-file-editor","title":"Linux file editor","text":"<p>Several standard text editors on most Linux systems:</p> <ul> <li><code>vi</code> visual editor</li> <li><code>ed</code> standard line editor</li> <li><code>ex</code> extended line editor</li> <li><code>emacs</code> a full screen editor</li> <li><code>pico</code> beginner's editor</li> <li><code>vim</code> advanced version of vi</li> </ul> <p>Will focus on <code>vi</code> because it is usually available on every Linux system and is easy to learn.</p>"},{"location":"linux-essentials/linux-administration/utility-commands-user-management/#most-common-vi-commands","title":"Most common <code>vi</code> commands","text":"<p><code>i</code> insert <code>Esc</code> escape out of any mode <code>r</code> replace <code>d</code> delete <code>:q!</code> quit without saving <code>:wq!</code> quit and save</p> <p>When you enter <code>vi</code> you will be in command mode. The other mode is the typing (insert) mode.</p> <p>To enter typing mode you hit <code>i</code> or \"insert\".</p> <p>To save you could shift + z z. Or you could do <code>:wq!</code></p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/","title":"Commands and permissions","text":"<p>Commands syntax:</p> <pre><code>command option(s) argument(s)\n</code></pre>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#options","title":"Options","text":"<p>Options modify the way a command works, and usually consist of a dash followed by a single letter.</p> <p>Multiple options can be grouped together after a single hyphen.</p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#arguments","title":"Arguments","text":"<p>Most commands are used with one or more arguments.</p> <p>Some commands assume a default argument if none is supplied.</p> <p>Arguments are optional for some commands and required by others.</p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#useful-commands","title":"Useful commands","text":"<p><code>whoami</code> to determine which user you are.</p> <p><code>pwd</code> to display your directory.</p> <p><code>cd</code> to move about directories.</p> <p><code>ls</code> to see items within working directory.</p> <p><code>cp</code> to copy a file from one directory to another.</p> <ul> <li>The third column in file info tells you the owner of the file.</li> <li>The fourth column is the group name for that file.</li> <li>Fifth column gives number of bytes for the file.</li> <li><code>ll</code> gives same result as <code>ls -l</code></li> </ul> <p><code>rm -f</code> to delete a file without confirming, <code>rm -r</code> to delete a directory.</p> <p><code>mkdir</code> to create a directory.</p> <p><code>man</code> with a command as argument to see man page for a command.</p> <p><code>date</code> gives the date on your system.</p> <p><code>more</code> gives output one page at a time. Piping with more is useful.</p> <p><code>tail</code> gives last line of an output. Also useful in piping.</p> <p><code>cat</code> reads contents of a file.</p> <p>To become a super user (root user) use <code>sm -</code> and enter your password.</p> <ul> <li>To leave root user account: <code>exit</code></li> </ul>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#permissions","title":"Permissions","text":"<p><code>r</code> - read <code>w</code> - write <code>x</code> - execute = running a program</p> <p>Each permission can be controlled at three different levels:</p> <p><code>u</code> - user <code>g</code> - group <code>o</code> - other = everyone on the system</p> <p>To see file or directory permissions run <code>ls -l</code>:</p> <p>Example: <code>-rwxrwxrwx</code></p> <p>First bit indicates a file, next three bits are user permissions, then next three are group, and last three are permissions for others.</p> <p><code>chmod</code> can be used to change permissions.</p> <p>Example: Removing group write permissions from file <code>testfile</code>: <code>chmod g-w testfile</code> Example: Removing write permissions for everyone from file <code>testfile</code>: <code>chmod a-w testfile</code></p>"},{"location":"linux-essentials/linux-command-line/commands-and-permissions/#file-ownership","title":"File ownership","text":"<p><code>chown</code> changes the ownership of a file.</p> <p>Example: To change the ownership from a user to root: <code>chown root testfile</code></p> <p><code>chgrp</code> changes the group ownership of a file.</p> <p>The <code>-R</code> option changes ownership recursively (everything within will also have ownership changed).</p> <p>Note: If a file you do not have ownership of is within a directory that you have permissions for, you can still delete/make changes to it. For this reason is it often important to perform recursive ownership changes to ensure they are properly applied for your case.</p> <p>Source: Linux for Absolute Beginners: Commands and Permissions by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/file-commands/","title":"File commands","text":""},{"location":"linux-essentials/linux-command-line/file-commands/#file-display-commands","title":"File display commands","text":"<ul> <li><code>cat</code> views entire content</li> <li><code>more</code> views one page at a time</li> <li><code>less</code> views content in reverse order, one page at time</li> <li><code>head</code> gives the first few lines</li> <li><code>tail</code> gets you the last lines of a file</li> </ul>"},{"location":"linux-essentials/linux-command-line/file-commands/#file-maintenance-commands","title":"File maintenance commands","text":"<ul> <li><code>cp</code> copies a file from one location to another</li> <li><code>rm</code> removes a file</li> <li><code>mv</code> used to move location of file from one to another, or rename it</li> <li><code>mkdir</code> makes a directoy</li> <li><code>rmdir</code> or <code>rm -r</code> removes directory</li> <li><code>chgrp</code> changes group ownership</li> <li><code>chown</code> changes ownership</li> </ul> <p>Source: Linux for Absolute Beginners: File Commands and Filters by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/","title":"File comparison and splitting","text":""},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#cut-command","title":"Cut command","text":"<p>Cut is a command utility that allows you to cut parts of lines from specific files or piped data and print the result to standard output.</p> <p>Can be used to cut parts1 of a line by a delimiter, byte position, and character.</p> <p><code>cat -c1 filename</code> list one character <code>cut -c1,2,4</code> pick and choose character(s) <code>cut -c1-3 filename</code> list range of characters <code>cut -c1-3, 6-8 filename</code> list by specific range of characters <code>cut -b1-3 filename</code> list by byte size <code>cut -d: -f 6 /etc/passwd</code> list first 6th column separated by : <code>cut -d: -f 6-7 /etc/passwd</code> list first 6 and 7th column separated by : <code>ls -l | cut -c2-4</code> only print user permissions of files/dir</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#compare-files","title":"Compare files","text":"<p><code>diff</code> compares line by line <code>cmp</code> compares byte by byte</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#comtining-and-plitting-files","title":"Comtining and plitting files","text":"<p>Multiple files can be combined into one, and one file can be split into multiple files.</p> <p>In times when we have huge files, there are times when we need to either split them or compress them to send them places.</p> <p><code>split -l 2 countries sep</code> splits the file countries into files with name <code>sep</code> containing 2 lines each from original countries file</p>"},{"location":"linux-essentials/linux-command-line/file-comparison-and-splitting/#linux-vs-windows-commands","title":"Linux vs. Windows commands","text":"<p>Listing of a directory: <code>dir</code> vs <code>ls -l</code> Rename a file: <code>ren</code> vs <code>mv</code> Copy a file: <code>copy</code> vs <code>cp</code> Move file: <code>move</code> vs <code>mv</code> Clear screen: <code>cls</code> vs <code>clear</code> Delete file: <code>del</code> vs <code>rm</code> Compare contents of files: <code>fc</code> vs <code>diff</code> Search for a word/string in a file: <code>find</code> vs <code>grep</code> Display command help: <code>command /?</code> vs <code>man command</code> Displays your location in the file system: <code>chdir</code> vs <code>pwd</code> Displays the time: <code>time</code> vs <code>date</code></p> <p>Source: Linux for Absolute Beginners: File Comparison and Splitting by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/","title":"Help commands and pipes","text":""},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#help-commands","title":"Help commands","text":"<p>3 types of help commands:</p> <ul> <li><code>whatis command</code></li> <li>Gives shorter version of command info</li> <li><code>command --help</code></li> <li>Longer version of help for command</li> <li><code>man command</code></li> <li>Full info for command</li> </ul>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#tab-and-up-arrow","title":"Tab and up arrow","text":"<p>Tab completes available commands, files, or directories.</p> <p>Up arrow gives the last executed command.</p>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#pipes","title":"Pipes","text":"<p>Pipes are used to connect the output of one command to the input of another command.</p> <p>The symbol for a pipe is <code>|</code>. Syntax for using pipes is:</p> <pre><code>command1 [arguments] | command2 [arguments]\n</code></pre>"},{"location":"linux-essentials/linux-command-line/help-commands-and-pipes/#adding-text-to-files","title":"Adding text to files","text":"<p>3 simple ways:</p> <ul> <li><code>vi</code> editor</li> <li>Redirect command output <code>&gt;</code> or <code>&gt;&gt;</code></li> <li><code>echo &gt;</code> or <code>&gt;&gt;</code></li> </ul> <p>Example using redirect: <code>echo \"Jerry is the main character in Seinfeld\" &gt; jerry</code> populates file <code>jerry</code> with that text.</p> <p>Doing it with <code>&gt;</code> will overwrite contents. <code>&gt;&gt;</code> will add to the existing contents.</p> <p>Can also send the output of a command to a file this way.</p> <p>Source: Linux for Absolute Beginners: Help Command and Pipes by Imran Afzal, Allison.</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/","title":"Text and grep commands","text":""},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#filterstext-processors-commands","title":"Filters/text processors commands","text":"<ul> <li><code>cut</code> cut output of command</li> <li><code>awk</code> list by the columns</li> <li><code>grep</code> and <code>egrep</code> search by keywords</li> <li><code>sort</code> sorts output</li> <li><code>uniq</code> no duplicates in output</li> <li><code>wc</code> word count</li> </ul> <p>Example of <code>grep</code>: To search for directories with user read and write permissions: <code>ls -l | grep drw</code></p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#grep-usage","title":"<code>grep</code> usage","text":"<p><code>grep keyword file</code> gives only the lines of <code>file</code> that contain <code>keyword</code> <code>grep -c keyword file</code> this searches for a keyword and counts it <code>grep -i KEYword file</code> searches for keyword but ignore case <code>grep -n keyword file</code> displays the matched lines and line numbers <code>grep -v keyword file</code> get everything but the search keyword <code>grep keyword file | awk '(print $1)'</code> gives only first columns of the lines returned <code>ls -l | grep Desktop</code> only pull results that include \"Desktop\" <code>egrep -i \"keyword|keyword2\" file</code> gives all lines matching either of the keywordsx</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#wc-usage","title":"<code>wc</code> usage","text":"<p>Reads either standard input or list of files and generates: newline count, word count, byte count.</p> <p><code>wc file</code> checks file line count, word count, byte count <code>wc -l file</code> gets number of lines in a file <code>wc -w file</code> gets number of words in a file <code>wc -b file</code> gets number of bytes in a file</p> <p><code>ls -l | wc -l</code> gives the number of files/directories you have within a location (plus 1 extra line counted)</p>"},{"location":"linux-essentials/linux-command-line/text-and-grep-commands/#awk-usage","title":"<code>awk</code> usage","text":"<p>Most of the time <code>awk</code> is used to extract fields from a file or from an output.</p> <p>Source: Linux for Absolute Beginners: Text and Grep Commands by Imran Afzal, Allison.</p>"},{"location":"solutions-architect/amazon-s3/","title":"Introduction to Amazon Simple Storage Service (S3)","text":"<p>Say you want to have an S3 bucket that your EC2 instance can read and write to.</p>"},{"location":"solutions-architect/amazon-s3/#creating-a-bucket","title":"Creating a bucket","text":"<ol> <li>Go to the S3 services page.</li> <li>Choose \"create bucket\"</li> <li>Names the bucket. Names can only have lowercase letters, numbers, or hyphens and must be globally unique</li> <li>Configure other settings, create the bucket</li> </ol>"},{"location":"solutions-architect/amazon-s3/#adding-files-to-the-bucket","title":"Adding files to the bucket","text":"<p>Can click on bucket, hit upload, and add files from your local machine to the bucket.</p>"},{"location":"solutions-architect/amazon-s3/#security-of-our-bucket","title":"Security of our bucket","text":"<p>Before connecting to EC2 instance, we want to check the security of the bucket to make sure everything is good.</p> <p>We want to configure permissions and test the bucket and object settings.</p> <p>To check that our bucket object is private we could try to access it by clocking on the object URL, and if we are denied access we know that the object is in face private.</p> <p>If we try to make an individual object public it will block out access because by default, Block Public Access will be turned on for the bucket.</p> <p>To change this, we go back to the main bucket page and navigate to the permissions tab. We deselect the block all public access option, and leave the others deselected as well.</p> <p>These permissions are not very restrictive and not best practices, but just for the purposes of this lab they are fine.</p> <p>Now we can navigate to the specific object once again and make it public via ACL.</p> <p>If we wish to grant access to an entire bucket rather than just one specific object, we need to use bucket policies, covered later on.</p>"},{"location":"solutions-architect/amazon-s3/#testing-connectivity-to-ec2-instance","title":"Testing connectivity to EC2 instance","text":"<p>We can connect to the instance like we did previously using Session Manager.</p> <p>We can list all of our S3 buckets from the home directory using the command <code>aws s3 ls</code>.</p> <p>To list all the objects in a specific bucket we can do: <code>aws s3 ls s3://nameofbucket</code></p> <p>Right now we are unable to copy files to the S3 bucket.</p> <p>We can head to the roles page within the IAM section, search for EC2InstanceProfileRole. This is the Role that the EC2 instance uses to connect to S3.</p> <p>Just as a reminder, IAM Roles define a set of permissions for users that are assumed temporarily.</p> <p>We copy the role ARN here: arn:aws:iam::319196556365:role/EC2InstanceProfileRole</p> <p>The ARN uniquely identifies AWS resources across all of AWS.</p> <p>We now navigate to the bucket permissions and find the bucket ARN: arn:aws:s3:::reportbucket28239482390</p> <p>Now, to create an S3 bucket policy, we can use the AWS Policy Generator.</p> <p>PutObject is for uploads to S3 and GetObject is for retrieving files from S3.</p>"},{"location":"solutions-architect/amazon-s3/#versioning-for-buckets","title":"Versioning for buckets","text":"<p>versioning is a way to keep multiple variants of an object in the same bucket. You can preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket.</p> <p>With versioning you can easily recover from both unintended user actions and application failures.</p> <p>Versioning is enabled by the bucket and not for individual objects.</p> <p>If files with the same name are uploaded, Amazon S3 always returns the latest version unless otherwise specified.</p> <p>You can view and access previous versions with the S3 Management Console when looking within your bucket, however, you need to alter your policy to include \"s3:GetObjectVersion\" to access the older version.</p> <p>When you delete an object that has versioning, a delete marker remains. When you permanently delete the delete marker, it effectively restores the object to its previous state.</p> <p>However, when deleting a specific version of an object no delete marker is created and the object is permanently deleted.</p>"},{"location":"solutions-architect/amazon-s3/#important-points-from-this-lab","title":"Important points from this lab","text":"<p>In an SIn an Amazon S3 bucket policy, which element specifies the AWS accounts or users that the policy applies to? Principal.</p> <p>What is the primary purpose of Amazon S3 bucket versioning? To preserve, retrieve, and restore every version of every object in a bucket</p> <p>What happens when you upload an object with the same name as an existing object in an S3 bucket? A new version is created if versioning is enabled, but otherwise the existing object is overwritten.</p> <p>What happens if you try to create an Amazon S3 bucket with a name that already exists? The bucket creation fails, and you receive an error message</p> <p>What is the default access setting for newly created S3 buckets? Private</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/architecting-fundamentals/","title":"Architecting fundamentals","text":""},{"location":"solutions-architect/architecting-fundamentals/#aws-services","title":"AWS services","text":"<ul> <li>Secure and robust</li> <li>Lots of services</li> <li>Pay as you go</li> </ul> <p>The main benefit is agility.</p> <p>Why customers move to AWS:</p> <ul> <li>Agility<ul> <li>Accelerate time to market</li> <li>Increase innovation</li> <li>Scale seamlessly</li> </ul> </li> <li>Complexity and risk<ul> <li>Optimize costs</li> <li>Minimize security vulnerabilities</li> <li>Reduce management complexity</li> </ul> </li> </ul>"},{"location":"solutions-architect/architecting-fundamentals/#categories-of-aws-services","title":"Categories of AWS services","text":"<p>Serverless:</p> <ul> <li>Amazon API Gateway<ul> <li>Create, publish, maintain, and secure RESTful and WebSocket APIs at any scale</li> </ul> </li> <li>Amazon Simple Queue Service (Amazon SQS)<ul> <li>Message queuing service that decouples and buffers communication between distributed application components</li> </ul> </li> <li>Amazon Simple Notification Service (Amazon SNS)<ul> <li>Messaging services enabling message delivery to multiple subscribers via push mechanisms like email, SMS, or Lambda</li> </ul> </li> <li>Amazon Kinesis<ul> <li>Real-time data streaming and processing at scale, enabling ingestion and analysis of large volumes of streaming data such as logs, events, and video</li> </ul> </li> </ul> <p>Networking and Content Delivery:</p> <ul> <li>Amazon Virtual Private Cloud (Amazon VPC)<ul> <li>Lets you create a private, isolated network within AWS where you can launch and manage your cloud resources</li> </ul> </li> <li>VPC endpoints<ul> <li>Allow you to privately connect your VPC to AWS services without needing to go over the public internet</li> </ul> </li> <li>VPC traffic security<ul> <li>Includes tools like security groups and network ACLs that help control who can send or receive data in your VPC</li> </ul> </li> <li>VPC peering connection<ul> <li>A way to link two VPCs so they can communicate with each other using private IP addresses</li> </ul> </li> <li>Hybrid networking<ul> <li>Connects your on-premises network to AWS so you can use both together smoothly</li> </ul> </li> <li>AWS Transit Gateway<ul> <li>A central hub that makes it easier to connect multiple VPCs and on-premises networks all in one place</li> </ul> </li> </ul> <p>Database:</p> <ul> <li>Amazon Relational Database Service (Amazon RDS)<ul> <li>Makes it easy to set up, run, and scale traditional SQL databases in the cloud without managing the hardware</li> </ul> </li> <li>AMazon DynamoDB, a NoSQL service<ul> <li>A fast, fully managed NoSQL database service designed for apps that need quick access to large amounts of unstructured data.</li> </ul> </li> </ul> <p>Security, Identity, and Compliance:</p> <ul> <li>Mechanisms to define identity and access management policies in AWS accounts<ul> <li>Use IAM policies and roles to control who can access which AWS resources and what actions they can take.</li> </ul> </li> <li>AWS services which enable you to implement security and identity policies<ul> <li>Services like AWS IAM, AWS Organizations, and AWS Config help manage permissions, track changes, and enforce security rules.</li> </ul> </li> <li>How to protect your AWS infrastructure from distributed denial of service (DDoS) attacks<ul> <li>AWS Shield and AWS WAF protect your applications by detecting and blocking harmful traffic before it reaches your services.</li> </ul> </li> </ul> <p>Management and Governance:</p> <ul> <li>AWS infrastructure management for applications<ul> <li>Services like AWS Systems Manager and AWS Config help you monitor, manage, and maintain your cloud resources.</li> </ul> </li> <li>AWS CloudFormation<ul> <li>Lets you describe your entire cloud setup in code so you can automate and consistently recreate your infrastructure.</li> </ul> </li> </ul> <p>Storage:</p> <ul> <li>Amazon Simple Storage Service (Amazon S3)<ul> <li>A highly scalable object storage service used to store and retrieve any amount of data, like files, backups, and media.</li> </ul> </li> <li>AWS Storage Gateway<ul> <li>Connects on-premises software with cloud storage to back up and archive data seamlessly.</li> </ul> </li> <li>Amazon FSx<ul> <li>Provides managed file systems in the cloud that support Windows, Lustre, and other workloads requiring shared storage.</li> </ul> </li> </ul> <p>AWS Cost Management:</p> <ul> <li>AWS Billing and Cost Management<ul> <li>Helps you track your usage, manage budgets, and forecast or analyze your AWS spending.</li> </ul> </li> </ul> <p>Containers:</p> <ul> <li>Microservices architecture<ul> <li>A way to build applications as a collection of small, independent services that can be developed and deployed separately.</li> </ul> </li> <li>Managing Microservices on AWS<ul> <li>Services like Amazon ECS, EKS, and AWS App Mesh help run, scale, and connect containerized microservices efficiently.</li> </ul> </li> </ul> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/aws-infrastructure/","title":"AWS infrastructure","text":""},{"location":"solutions-architect/aws-infrastructure/#aws-data-centers-availability-zones","title":"AWS data centers &amp; availability zones","text":"<p>Undisclosed facilities.</p> <p>Use proprietary AWS resources.</p> <p>Availability zones are the most granular form that we refer to when talking about data centers. Availability zones are clusters of data centers, and are interconnected. They help to protect against localized failures.</p> <p>When you launch an instance, you can select an Availability Zone or let AWS choose one for you.</p>"},{"location":"solutions-architect/aws-infrastructure/#aws-regions","title":"AWS regions","text":"<p>Isolated from each other, can have multiple per country. Contain multiple availability zones.</p> <p>Every time you see something like: us-east-1</p> <p>This means we are talking about the first region of the east of the US.</p> <p>If you see us-east-1b, we are talking about an availability zone.</p> <p>Sometimes a service might be deployed in an availability zone, and sometimes it might be deployed in a region.</p>"},{"location":"solutions-architect/aws-infrastructure/#factors-impacting-region-selection","title":"Factors impacting region selection","text":"<ul> <li>Governance<ul> <li>You should consider legal requirements</li> </ul> </li> <li>Latency</li> <li>Close proximity to customers means better performance</li> <li>Service availability</li> <li>Not all AWS services are available in all Regions</li> <li>Cost</li> <li>Different Regions have different costs</li> </ul>"},{"location":"solutions-architect/aws-infrastructure/#aws-local-zones","title":"AWS Local Zones","text":"<p>Specific locations that have small, specific amount of services available for workloads that require low latency like live streaming, etc.</p> <p>Essentially for highly demanding applications that require single-digit millisecond latency to end users.</p>"},{"location":"solutions-architect/aws-infrastructure/#edge-locations","title":"Edge locations","text":"<p>Locations around the world that has limited number of services, like Route 53 or CloudFront (which caches data at these locations).</p> <p>So if you have workloads where you are cachine content and want to increase probability that this content will be cached close to users, this might be for you.</p> <p>Use case of edge locations is to bring the content closer to the customer for better performance.</p>"},{"location":"solutions-architect/aws-infrastructure/#aws-local-zone-and-edge-location-features","title":"AWS Local Zone and edge location features","text":"<p>AWS Local Zones:</p> <ul> <li>Can run compute, storage, and databases</li> <li>Low latency</li> <li>Local data processing</li> <li>Consistent AWS experience</li> </ul> <p>Edge locations:</p> <ul> <li>Caching of data</li> <li>Fast delivery of content</li> <li>Better user experience</li> </ul> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/aws-management-console/","title":"AWS amangement console","text":""},{"location":"solutions-architect/aws-management-console/#things-to-note-about-aws-management-console","title":"Things to note about AWS management console","text":""},{"location":"solutions-architect/aws-management-console/#region","title":"Region","text":"<p>Can change your region in top right and can set default region in user settings.</p>"},{"location":"solutions-architect/aws-management-console/#finding-services","title":"Finding services","text":"<p>Can click on the squares in top left to see favourites, all services, etc. Can also search.</p> <p>Can add and remove favourite services.</p>"},{"location":"solutions-architect/aws-management-console/#widgets","title":"Widgets","text":"<p>Can have widgets on the home page, such as your favourite services.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/compute-services/","title":"Compute services","text":""},{"location":"solutions-architect/compute-services/#evolution-of-aws-compute","title":"Evolution of AWS compute","text":""},{"location":"solutions-architect/compute-services/#pre-cloud","title":"Pre-cloud","text":"<p>Physical on-premises servers.</p>"},{"location":"solutions-architect/compute-services/#amazon-ec2","title":"Amazon EC2","text":"<p>Virtualization</p>"},{"location":"solutions-architect/compute-services/#amazon-elastic-container-service-amazon-ecs","title":"Amazon Elastic Container Service (Amazon ECS)","text":"<p>Containerization</p>"},{"location":"solutions-architect/compute-services/#aws-lambda","title":"AWS Lambda","text":"<p>Serverless</p>"},{"location":"solutions-architect/compute-services/#aws-fargate","title":"AWS Fargate","text":"<p>Serverless containerization</p>"},{"location":"solutions-architect/compute-services/#aws-graviton-processors","title":"AWS Graviton processors","text":"<p>Specialized processors</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/dynamodb/","title":"Introduction to Amazon DynamoDB","text":"<p>DynamoDB is a fast and flexible NoSQL database supporting both document and key-value data models.</p> <p>Each table requires a primary key, and sometimes has a sort key as well. The combo of primary key and sort key uniquely identifies each item in a DynamoDB table.</p> <p>When creating a table you are able to specify both the primary key and sort key.</p> <p>Each table contains multiple items. An item is a group of attributes that is uniquely identifiable among all the other items. Items are like rows. No limit to number of items you can store in a table.</p> <p>Each item composed of one or more attributes. Attributes are fundamental data elements. Similar to columns in other database systems, but each item can have different attributes.</p> <p>Each item requires the primary key and sort key (if used), but otherwise you can use different attributes.</p>"},{"location":"solutions-architect/dynamodb/#creating-and-modifying-items","title":"Creating and modifying items","text":"<p>You can create and view items via the \"explore items: music\" page.</p> <p>Faster ways to load data into DynamoDB include using the AWS Data Pipeline, programmatically loading data, or using one of the free tools available on the internet.</p> <p>You can also modify existing items.</p>"},{"location":"solutions-architect/dynamodb/#querying-and-scanning","title":"Querying and scanning","text":"<p>There are two ways to query a DynamoDB table: Query and Scan.</p> <p>A query operation finds items based on primary key and optionally sort key. It is fully indexed and so it runs very fast. A query is the most efficient way to retrieve data from a DynamoDB table.</p> <p>Scanning involves looking through every item in a table, so it is less efficient and can take significant time for larger tables.</p>"},{"location":"solutions-architect/dynamodb/#knowledge-check","title":"Knowledge check","text":"<p>Which statement BEST describes the flexibility of adding attributes to items in a DynamoDB table? New attributes can be added to some items without affecting others</p> <p>Which of the following statements is TRUE about inserting data into a DynamoDB table? You can insert items with different attributes into the same table</p> <p>What should you consider before deleting a DynamoDB table? The need for a backup of the data</p> <p>Which operation is used to retrieve data from a DynamoDB table based on specific criteria? Query</p> <p>What is the relationship between a Primary Key and a Sort Key in an Amazon DynamoDB table? They uniquely identify each item when used in combination</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/","title":"Elastic IP addresses and NAT gateways","text":""},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/#elastic-ip-address","title":"Elastic IP address","text":"<p>Elastic IP address is static, public IPv4 address for dynamic cloud computing.</p> <p>It can be associated with any instance or network interface for any VPC in your account.</p> <p>Can mask failure of an instance by quickly remapping address to another instance in VPC.</p> <p>Purpose is to permit association with instance or network interface.</p> <p>Can be thought of as a business phone number - you keep same one even if you move offices or switch phones.</p>"},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/#elastic-network-interface","title":"Elastic network interface","text":"<p>Virtual network interface that:</p> <ul> <li>Can be moved amongst different instances in same AZ</li> <li>Maintains same IP address, elastic IP address, MAC address</li> </ul>"},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/#nat-gateways","title":"NAT gateways","text":"<p>Using NAT, private IP networks (like for databases and backend services) using unregistered IP addresses are able to connect to the internet.</p> <p>One-way outbound connection between pricate subnet instances and internet or other AWS services.</p>"},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/#associate-elastic-ip-addresses-with-resources","title":"Associate elastic IP addresses with resources","text":"<p>Elastic IP address can be associated with any instance or network interface in any VPC.</p>"},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/#connecting-private-subnets-to-the-internet","title":"Connecting private subnets to the internet","text":"<p>NAT gateway can be used as a one-way connection between private subnet instances and the internet or other aws services.</p> <p>How to connect component in private subnet to internet:</p> <ol> <li>Route table for private subnet sends all IPv4 internet traffic to NAT gateway</li> <li>NAT gateway uses Elastic IP as source IP for traffic from private subnet</li> <li>Route table for public subnet sends all internet traffic to internet gateway. Not supported for IPv6</li> </ol>"},{"location":"solutions-architect/elastic-ip-addresses-and-nat-gateways/#deploy-vpc-across-multiple-availability-zones","title":"Deploy VPC across multiple availability zones","text":"<p>This creates architecture achieving high availability, distributing traffic while secure.</p> <p>If you have an outage in one AZ you can fail over to other.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/ip-addressing/","title":"IP addressing","text":"<p>When you see an IP address slash something, it means we are representing a range of IP addresses.</p> <p>The bigger this number, the smaller the network is.</p> <p>The start identifies the network, the middle identifies the host, and the end identifies the range.</p>"},{"location":"solutions-architect/ip-addressing/#ipv4-addresses","title":"IPv4 addresses","text":"<p>32-bit addresses. Bits grouped in four sets of 8 bits called octets.</p> <p>First two octets identify network, last two designate the resource within the network.</p>"},{"location":"solutions-architect/ip-addressing/#ipv6-addresses","title":"IPv6 addresses","text":"<p>128-bit addresses. Eight groups of four hexadecimal digits with colon as separator.</p>"},{"location":"solutions-architect/ip-addressing/#classless-inter-domain-routing-cidr","title":"Classless inter-domain routing (CIDR)","text":"<p>Method of assigning IP addresses improving efficiency of address distribution.</p> <p>Addresses specified in CIDR block.</p> <p>By default all VPCs and subnets need to have IPc4 CIDR blocks.</p> <p>Identifies network using dot notation and subnet mask using slash notation.</p>"},{"location":"solutions-architect/ip-addressing/#aws-supported-cidr-ranges","title":"AWS supported CIDR ranges","text":"<p>Network can be identified using 16-28 bits in 32 bit IPv4 address. Resources in subnet can be identified using 4-16 bits in 32 bit IPv4 address. </p>"},{"location":"solutions-architect/launching-ec2-instances/","title":"Launching EC2 instances","text":""},{"location":"solutions-architect/launching-ec2-instances/#ec2-page","title":"EC2 page","text":"<p>From the AWS Management Console, there is a search bar you can use to navigate to the pages for different services.</p> <p>The EC2 page is all about EC2s, and contains info for the particular region that is selected. You can of course launch instances from this page.</p>"},{"location":"solutions-architect/launching-ec2-instances/#service-quotas-page","title":"Service Quotas page","text":"<p>The service quotas page has info on service quota (limits) for various services. It is possible to request a service quota increase.</p>"},{"location":"solutions-architect/launching-ec2-instances/#ami-catalog","title":"AMI Catalog","text":"<p>The AMI catalog is the page for AMIs (Amazon Machine Image). AMIs are basically EC2 configurations specifying operating system, application server, applications, etc. that can be used to launch pre-configured EC2 instances.</p> <p>Basically a way to store your environment configuration.</p> <p>Found under the images section of the sidebar on the EC2 page because they are essentially snapshots of a system's state.</p>"},{"location":"solutions-architect/launching-ec2-instances/#to-launch-an-ec2-instance","title":"To launch an EC2 instance...","text":"<ol> <li>Name it</li> <li>Select AMI or configure it yourself</li> <li>Select the instance type</li> <li>Select the key pair</li> <li>Select the VPC (default is fine too)</li> <li>Hit \"launch instance\"</li> </ol> <p>You can review the instance by heading to the \"view all instances\" page.</p> <p>At first it will be pending, but once it is running you can connect to it and use it in the same way that you'd use a computer in front of you.</p>"},{"location":"solutions-architect/launching-ec2-instances/#instance-states","title":"Instance states","text":"<p>When you stop and start your instance, you lose any data in the instance store. However, you retain its private IPv4 address, meaning that an Elastic IP address associated with the private IPv4 address or network interface is still associated with your instance.</p> <p>The significance of retaining the IP is that every component of your architecture that could be reliant on IP is not disrupted.</p> <p>You can also reboot your instance. It remains on the same computer and this does not disrupt the instance store or anything like that. Same as rebooting an operating system.</p> <p>Instance can also be put into hibernation, saving the contents from the instance memory to your EBS root volume. The instance's Amazon EBS root volume and any attacked Amazon EBS data volumes persist. Other stuff like IP is also retained.</p> <p>Instance termination is when you no longer need an instance. It remains on the console for a bit then the entry is automatically deleted.</p>"},{"location":"solutions-architect/launching-ec2-instances/#instance-details","title":"Instance details","text":"<p>To review instance details you click on the \"actions\" dropdown and choose \"view details\". This shows you a summary of the instance's attributes like addresses, state, type, etc.</p>"},{"location":"solutions-architect/launching-ec2-instances/#runing-commands-when-you-launch-an-ec2-instance-with-user-data-input","title":"Runing commands when you launch an EC2 instance with user data input","text":"<p>You can actually include a shell script in the \"user data\" field that will be run when the EC2 instance is launched. In the tutorial this was used to get a basic web application up and running.</p>"},{"location":"solutions-architect/launching-ec2-instances/#accessing-an-ec2-instance","title":"Accessing an EC2 instance","text":"<p>Can use Session Manager to connect to an instance. This allows you to manage your instance with a CLI.</p> <p>If you plan to connect to your instance using SSH, you must specify a key pair. Essentially when the instance boots for the first time that key is stored on the virtual machine, and when you connect to your Linux instance using SSH you must specify the private key corresponding to that public key stored on the VM.</p> <p>You can now navigate the EC2 instance (Linux VM) as if it was just a CLI on a Linux machine.</p>"},{"location":"solutions-architect/launching-ec2-instances/#instance-types","title":"Instance types","text":"<p>Different instance types like t3.small and t3.micro represent different hardware configurations.</p>"},{"location":"solutions-architect/launching-ec2-instances/#modifying-storage-volumes","title":"Modifying storage volumes","text":"<ol> <li>Go to actions -&gt; view details</li> <li>Go to storage</li> <li>Go to block devices section</li> <li>Click on the volume ID for the root device</li> <li>On the volumes page select the volume</li> <li>Choose actions -&gt; modify</li> </ol> <p>You can change the volume type and the size.</p> <p>When an EBS volume is modified it goes through a series of states, and this process might take some time.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/managing-multiple-accounts/","title":"Managing multiple accounts","text":""},{"location":"solutions-architect/managing-multiple-accounts/#reasons-to-use-multiple-accounts","title":"Reasons to use multiple accounts","text":"<ul> <li>Many teams</li> <li>Security and compliance</li> <li>Billing and cost insights</li> <li>Isolation</li> <li>Business process</li> </ul>"},{"location":"solutions-architect/managing-multiple-accounts/#aws-organizations","title":"AWS Organizations","text":"<p>Put a bunch of accounts in one place where you can manage them all from.</p> <p>Can further group those accounts into organizational units (OUs) and apply different access policies to each.</p> <p>Key characteristics:</p> <ul> <li>Consolidated billing</li> <li>Centralized management</li> <li>Hierarchical grouping</li> <li>Integration w/ IAM</li> <li>Integration w/ AWS services</li> </ul>"},{"location":"solutions-architect/managing-multiple-accounts/#with-vs-without-aws-organizations","title":"With vs. without AWS organizations","text":"<p>Without organizations, applying a standardized policy would mean redundantly applying the same policy across many accounts. With organizations you can use service control policies to specify max permissions for accounts in organization.</p>"},{"location":"solutions-architect/managing-multiple-accounts/#iam-policies-with-scps","title":"IAM policies with SCPs","text":"<p>Apply SCP to organization to define guardrail. Attach IAM policies to users or resources.</p>"},{"location":"solutions-architect/managing-multiple-accounts/#example","title":"Example","text":"<p>Could have an Organizations SCP allowing ec2 and s3.</p> <p>Could have IAM identity-based permissions allowing ec2 and iam.</p> <p>These interact, and what ends up being allowed is ec2 because it is explicitly allowed by both.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/principals-and-identities/","title":"Principals and identities","text":"<p>The principal is who is performing an action in AWS.</p>"},{"location":"solutions-architect/principals-and-identities/#aws-account-root-user","title":"AWS account root user","text":"<p>Can do anything, like root user in Linux operating system. Should not generally be used for day-to-day interactions.</p>"},{"location":"solutions-architect/principals-and-identities/#identity-and-access-management-iam","title":"Identity and access management (IAM)","text":"<p>Web service for controlling access to your AWS resources.</p> <p>This is the tool for managing all types of access to your resources in one place, with fine control over permissions. This helps you define who has permissions to which API calls</p> <p>The place where we do authentication and authorization. Authentication is proving that I am who I say I am.</p>"},{"location":"solutions-architect/principals-and-identities/#principals","title":"Principals","text":"<p>Principal can make a request for an action or operation on an AWS resource. Can be a person, application, federated user, or assumed role.</p>"},{"location":"solutions-architect/principals-and-identities/#iam-users","title":"IAM users","text":"<p>Have credentials and permissions. Policies can be attached to them to control what they can do.</p>"},{"location":"solutions-architect/principals-and-identities/#how-do-iam-users-make-api-calls-and-how-are-they-restricted","title":"How do IAM users make API calls and how are they restricted?","text":"<p>So they can do stuff through the AWS Management Console, just with a password.</p> <p>They can also access programmatically, using the AWS CLI (you can install this to your computer) or AWS SDKs (development kits for using AWS services through popular programming languages).</p> <p>These programmatic options use access key IDs and secret keys.</p>"},{"location":"solutions-architect/principals-and-identities/#setting-permissions-with-iam-policies","title":"Setting permissions with IAM policies","text":"<p>You can define your own policies and apply them to IAM users.</p> <p>We apply the principle of least privilege when defining policies.</p>"},{"location":"solutions-architect/principals-and-identities/#iam-user-groups","title":"IAM user groups","text":"<p>Can also apply policies to a group rather than just a user. So these are IAM user groups. Users can inherit permissions from these groups.</p>"},{"location":"solutions-architect/principals-and-identities/#iam-roles","title":"IAM roles","text":"<p>Roles delegate set permissions to certain users of services.</p> <p>This is good for giving someone permissions for a short period of time, because these permissions are valid only while the role is active.</p>"},{"location":"solutions-architect/principals-and-identities/#assuming-a-role","title":"Assuming a role","text":"<p>So you can use an API call to assume a role, this returns temporary credentials that you can use for a period of time.</p>"},{"location":"solutions-architect/principals-and-identities/#iam-policy-assignments","title":"IAM policy assignments","text":"<p>Assigned to IAM users, groups, roles. Role is assumed. IAM user can assume a role, AWS resource itself can assume a role because it needs to perform a certain action within AWS.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/security-policies/","title":"Security policies","text":"<p>Identity-based policies and resource-based policies grant permissions to allow or deny actions. You define the permission of a principal (person) or resource.</p> <p>IAM permission boundaries and AWS service control policies (SCPs) are used to set boundaries in an organization to set upper boundaries. Broad approach, defining maximum permissions for an IAM user or group.</p> <p>IAM identity-based policies are assigned to users, groups, and roles, while IAM resource-based policies are assigned to resources.</p> <p>Resource-based policies also include a principal that controls what someone is allowed to do with that resource.</p>"},{"location":"solutions-architect/security-policies/#identity-based-policies","title":"Identity-based policies","text":"<p>Can be managed or inline. Managed are managed by AWS or customer.</p> <p>Inline policies are one-to-one with a single user, group, or role.</p>"},{"location":"solutions-architect/security-policies/#resource-based-policies","title":"Resource-based policies","text":"<p>Inline policies for resources.</p> <p>Grant permission to the principal specified in the policy to access resources.</p> <p>Principals can be in the same account as the resource or other accounts.</p>"},{"location":"solutions-architect/security-policies/#permission-boundaries","title":"Permission boundaries","text":"<p>Can use a managed policy as the permissions boundary for a user or role, and them no identity-based policy can grant permissions past that permission boundary.</p>"},{"location":"solutions-architect/security-policies/#aws-organizations-service-control-policies","title":"AWS organizations service control policies","text":"<p>Can use service control policies to set maximum permissions for account members or organization or organizational unit.</p>"},{"location":"solutions-architect/security-policies/#access-control-lists-acls","title":"Access control lists (ACLs)","text":"<p>Control which principals in other accounts can access a resource to which the ACL is attached.</p> <p>Similar to resource-based policies. Only policy type not using the JSON structure.</p>"},{"location":"solutions-architect/security-policies/#defense-in-depth","title":"Defense in depth","text":"<p>Strategy with goal of having multiple layers of security. Involves having multiple security controls at every layer of a request.</p>"},{"location":"solutions-architect/security-policies/#components-of-a-policy","title":"Components of a policy","text":"<p>Effect: What is the policy doing? Allowing or denying?</p> <p>Principal: Account, user, or role that the policy applies to.</p> <p>Action: What actions are we applying this effect to?</p> <p>Resource: Which resources does this policy apply to?</p> <p>Condition: Conditions for the policy to apply.</p>"},{"location":"solutions-architect/security-policies/#how-iam-policies-are-evaluated","title":"How IAM policies are evaluated","text":"<p>First checks if action is explicitly denied.</p> <p>Then checks if action is explicitly allowed.</p> <p>If it is, then it allows the action to be performed.</p> <p>If not, then it denies the action.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/vpc-fundamentals/","title":"VPC fundamentals","text":"<p>Can imagine the VPC as a logical isolation for your workloads.</p> <p>It is at the region level, and so can span different availability zones.</p>"},{"location":"solutions-architect/vpc-fundamentals/#amazon-virtual-private-cloud","title":"Amazon Virtual Private Cloud","text":"<p>Your network environment in the cloud.</p> <p>Can use VPC to launch AWS resources into virtual network you have defined.</p> <p>Deployed into regions, can host resources from any AZ within region.</p> <p>Using a VPC allows you to essentially create your own section of the cloud with your own rules, where your resources can live.</p>"},{"location":"solutions-architect/vpc-fundamentals/#subnets","title":"Subnets","text":"<p>Range of IPs in your VPC.</p> <p>AWS resources can be launched into a specific subnet.</p> <p>A public subnet can be used for resources that are to be connected to the internet and a private subnet can be used for resources that won't be connected to the internet.</p> <p>A subset resides in a single availability zone.</p>"},{"location":"solutions-architect/vpc-fundamentals/#public-subnets","title":"Public subnets","text":"<p>Use:</p> <ul> <li>Internet gateways that allow your resources to communicate with the internet</li> <li>Route tables: rules VPC uses to route network traffic. In public subnet, includes route to internet gateway</li> <li>Public IP addresses that can be reached from the internet</li> <li>Private IP addresses that are only reachable on the network</li> </ul>"},{"location":"solutions-architect/vpc-fundamentals/#internet-gateways","title":"Internet gateways","text":"<p>Horizontally scaled. Redundant. Highly available.</p> <p>Horizontal scaling is like adding more copies of something, while vertical scaling is like upgrading the existing copy.</p> <p>Permits communication between instances within VPC and internet.</p> <p>Serves two purposes:</p> <ol> <li>Provides target in route table for internet-routable traffic.</li> <li>Protects IP addresses on network by perfroming network address translation (NAT)</li> </ol> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/vpc-traffic-security/","title":"VPC traffic security","text":"<p>Network ACLs act as stateless firewall on the entire subnet.</p> <p>Security groups are virtual firewalls acting on the instance level.</p>"},{"location":"solutions-architect/vpc-traffic-security/#inbound-and-outbound-ipv4-traffic","title":"Inbound and outbound IPv4 traffic","text":"<p>Every default VPC comes with a modifiable default network ACL. By default it allows all inbound and outbound IPv4 traffic.</p> <p>Custom ACLs by default deny all inbound and outbound traffic.</p>"},{"location":"solutions-architect/vpc-traffic-security/#network-acl-rules","title":"Network ACL rules","text":"<p>Components of a network ACL rule:</p> <ul> <li>Rule number</li> <li>Type (type of traffic)</li> <li>Protocol</li> <li>Port range (listening port for the traffic)</li> <li>Source (for inbound traffic)</li> <li>Destination (for outbound traffic)</li> <li>Allow or deny</li> </ul>"},{"location":"solutions-architect/vpc-traffic-security/#security-groups","title":"Security groups","text":"<p>These allow traffic based on IP protocol, port, or IP address and use stateful rules.</p> <p>By default they include an outbound rule allowing all outbound traffic. If no outbound rules, no outbound traffic from that instance.</p> <p>Security groups are stateful.</p>"},{"location":"solutions-architect/vpc-traffic-security/#security-group-chaining","title":"Security group chaining","text":"<p>With a chain of security groups you can set up inbound and outbound rules in a way so that the traffic can only flow from top tier to bottom and back again.</p>"},{"location":"solutions-architect/vpc-traffic-security/#security-groups-vs-network-acls","title":"Security groups vs. Network ACLs","text":"<ul> <li>Security groups are a firewall for EC2 instances, and network ACLs are a firewall for subnets</li> <li>Security groups control traffic at instance level, and ACLs control traffic at subnet level</li> <li>Security groups only support allow rules, while network ACLs support both allow and deny rules</li> <li>Security groups are stateful while network ACLs stateless</li> <li>Security groups need to be assigned to instances while network ACLs automatically applied when instances added to subnet</li> </ul>"},{"location":"solutions-architect/vpc-traffic-security/#how-to-make-a-subnet-public","title":"How to make a subnet public?","text":"<p>Route outbound traffic through the internet gateway.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"},{"location":"solutions-architect/well-architected-framework/","title":"Well-Architected Framework","text":""},{"location":"solutions-architect/well-architected-framework/#aws-architect-responsibilities","title":"AWS architect responsibilities","text":"<p>Plan:</p> <ul> <li>Set technical cloud strategy with business leads</li> <li>Analyze solutions for business needs and requirements</li> </ul> <p>What is the return on investment?</p> <p>Research:</p> <ul> <li>Investigate cloud services specs and workload requirements</li> <li>Review existing workload architectures</li> <li>Design prototype solutions</li> </ul> <p>What does the customers want? How can I create that architecture?</p> <p>Build:</p> <ul> <li>Design the transformation roadmap with milestones, work streams, and owners</li> <li>Manage the adoption and migration</li> </ul> <p>Start building and designing the roadmap.</p>"},{"location":"solutions-architect/well-architected-framework/#aws-well-architected-framework-pillars","title":"AWS Well-Architected Framework pillars","text":"<ul> <li>Security<ul> <li>Apply at all layers</li> <li>Enforce principal of least privilege</li> <li>Use multi-factor authentication (MFA)</li> </ul> </li> <li>Performance Efficiency<ul> <li>Reduce latency</li> <li>Use serverless architecture</li> <li>Incorporate monitoring</li> </ul> </li> <li>Cost Optimization<ul> <li>Analyze and attribute expenditures</li> <li>Use cost-effective resources</li> <li>Stop guessing</li> </ul> </li> <li>Operational Excellence<ul> <li>Perform operations with code</li> <li>Test response for unexpected events</li> </ul> </li> <li>Reliability<ul> <li>Recover from failure</li> <li>Test</li> </ul> </li> <li>Sustainability<ul> <li>Understand  your impact</li> <li>Maximize utilization</li> </ul> </li> </ul> <p>AWS well-architected framework is tool for optimizing in these areas and comparing your current implementation against new offerings.</p> <p>Acts as central place for best practices and guidance.</p> <p>Basically a formally defined framework that can be used as a reference of best practices for customers and AWS partners, and to evaluate architectures and make sure things scale well over time.</p> <p>Main idea is to define workload, conduct architectural review, and apply best practices.</p> <p>Source: AWS Certified Solutions Architect - Associate (Subscription - Partner Subscription), AWS Training &amp; Certification.</p>"}]}